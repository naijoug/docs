import{_ as l}from"./plugin-vue_export-helper-x3n3nnut.js";import{r as a,o as r,c as i,b as e,e as n,d as t}from"./app-j-heE4gB.js";const s={},h=e("blockquote",null,[e("p",null,"LLMs : Large Language Models (大语言模型)")],-1),c=e("h2",{id:"reference",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#reference","aria-hidden":"true"},"#"),n(" reference")],-1),u={href:"https://github.com/eugeneyan/open-llms",target:"_blank",rel:"noopener noreferrer"},p=e("blockquote",null,[e("p",null,"🤖 A list of open LLMs available for commercial use.")],-1),_={href:"https://github.com/datawhalechina/self-llm",target:"_blank",rel:"noopener noreferrer"},d=e("blockquote",null,[e("p",null,"《开源大模型食用指南》基于Linux环境快速部署开源大模型，更适合中国宝宝的部署教程")],-1),f={href:"https://github.com/zhenbench/z-bench",target:"_blank",rel:"noopener noreferrer"},g=e("blockquote",null,[e("p",null,"Z-Bench 1.0 by 真格基金：一个麻瓜的大语言模型中文测试集。Z-Bench is a LLM prompt dataset for non-technical users, developed by an enthusiastic AI-focused team in Zhenfund")],-1),b={href:"https://datawhalechina.github.io/llm-universe/#/",target:"_blank",rel:"noopener noreferrer"},m={href:"https://github.com/datawhalechina/llm-universe",target:"_blank",rel:"noopener noreferrer"},L={href:"https://github.com/songquanpeng/one-api",target:"_blank",rel:"noopener noreferrer"},k=e("blockquote",null,[e("p",null,"OpenAI 接口管理 & 分发系统，支持 Azure、Anthropic Claude、Google PaLM 2、智谱 ChatGLM、百度文心一言、讯飞星火认知、阿里通义千问、360 智脑以及腾讯混元，可用于二次分发管理 key，仅单可执行文件，已打包好 Docker 镜像，一键部署，开箱即用. OpenAI key management & redistribution system, using a single API for all LLMs, and features an English UI.")],-1),M={href:"https://dify.ai",target:"_blank",rel:"noopener noreferrer"},A={href:"https://github.com/langgenius/dify",target:"_blank",rel:"noopener noreferrer"},C=e("blockquote",null,[e("p",null,"Dify is an open-source LLM app development platform. Dify's intuitive interface combines AI workflow, RAG pipeline, agent capabilities, model management, observability features and more, letting you quickly go from prototype to production.")],-1),y=e("h2",{id:"gpt",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#gpt","aria-hidden":"true"},"#"),n(" GPT")],-1),v={href:"https://fastgpt.in",target:"_blank",rel:"noopener noreferrer"},q={href:"https://github.com/labring/FastGPT",target:"_blank",rel:"noopener noreferrer"},G=e("blockquote",null,[e("p",null,"FastGPT is a knowledge-based platform built on the LLMs, offers a comprehensive suite of out-of-the-box capabilities such as data processing, RAG retrieval, and visual AI workflow orchestration, letting you easily develop and deploy complex question-answering systems without the need for extensive setup or configuration.")],-1),P={href:"https://github.com/nomic-ai/gpt4all",target:"_blank",rel:"noopener noreferrer"},w={href:"https://gpt4all.io",target:"_blank",rel:"noopener noreferrer"},T=e("blockquote",null,[e("p",null,"gpt4all: an ecosystem of open-source chatbots trained on a massive collections of clean assistant data including code, stories and dialogue")],-1),I={href:"https://github.com/juncongmoo/minichatgpt",target:"_blank",rel:"noopener noreferrer"},z=e("blockquote",null,[e("p",null,"🔥 To Train ChatGPT In 5 Minutes with ColossalAI")],-1),B={href:"https://github.com/imartinez/privateGPT",target:"_blank",rel:"noopener noreferrer"},x=e("blockquote",null,[e("p",null,"Interact privately with your documents using the power of GPT, 100% privately, no data leaks")],-1),V={href:"https://github.com/mattzcarey/code-review-gpt",target:"_blank",rel:"noopener noreferrer"},O=e("blockquote",null,[e("p",null,"Your personal code reviewer powered by LLMs (OpenAI GPT-3.5/4, Llama, Falcon, Azure AI) & Embeddings ⚡️ Improve code quality and catch bugs before you break production 🚀")],-1),F=e("h2",{id:"llama",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#llama","aria-hidden":"true"},"#"),n(" LLaMa")],-1),N={href:"https://github.com/facebookresearch/llama",target:"_blank",rel:"noopener noreferrer"},R={href:"https://ai.facebook.com/blog/large-language-model-llama-meta-ai/",target:"_blank",rel:"noopener noreferrer"},U=e("blockquote",null,[e("p",null,"Inference code for LLaMA models")],-1),D={href:"https://github.com/ggerganov/llama.cpp",target:"_blank",rel:"noopener noreferrer"},E=e("blockquote",null,[e("p",null,"Port of Facebook's LLaMA model in C/C++")],-1),S={href:"https://github.com/juncongmoo/chatllama",target:"_blank",rel:"noopener noreferrer"},Z=e("blockquote",null,[e("p",null,"ChatLLaMA 📢 Open source implementation for LLaMA-based ChatGPT runnable in a single GPU. 15x faster training process than ChatGPT")],-1),j={href:"https://github.com/juncongmoo/pyllama",target:"_blank",rel:"noopener noreferrer"},K=e("blockquote",null,[e("p",null,"🦙 LLaMA - Run LLM in A Single 4GB GPU")],-1),W=e("h2",{id:"alpaca",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#alpaca","aria-hidden":"true"},"#"),n(" Alpaca")],-1),H=e("li",null,[e("a",{href:"https//github.com/tatsu-lab/stanford_alpaca"},"Stanford Alpaca"),e("blockquote",null,[e("p",null,"An Instruction-following LLaMA Model")])],-1),Y={href:"https://github.com/tloen/alpaca-lora",target:"_blank",rel:"noopener noreferrer"},J=e("blockquote",null,[e("p",null,"Instruct-tune LLaMA on consumer hardware")],-1),Q={href:"https://github.com/ymcui/Chinese-LLaMA-Alpaca",target:"_blank",rel:"noopener noreferrer"},X=e("blockquote",null,[e("p",null,"中文LLaMA&Alpaca大语言模型+本地CPU/GPU部署 (Chinese LLaMA & Alpaca LLMs)")],-1),$={href:"https://github.com/Beomi/KoAlpaca",target:"_blank",rel:"noopener noreferrer"},ee=e("blockquote",null,[e("p",null,"KoAlpaca: Korean Alpaca Model based on Stanford Alpaca (feat. LLAMA and Polyglot-ko)")],-1),ne=e("h2",{id:"vicuna",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#vicuna","aria-hidden":"true"},"#"),n(" Vicuna")],-1),oe={href:"https://github.com/lm-sys/FastChat",target:"_blank",rel:"noopener noreferrer"},te=e("blockquote",null,[e("p",null,"An open platform for training, serving, and evaluating large language models. Release repo for Vicuna and FastChat-T5.")],-1),le={href:"https://github.com/Facico/Chinese-Vicuna",target:"_blank",rel:"noopener noreferrer"},ae=e("blockquote",null,[e("p",null,"Chinese-Vicuna: A Chinese Instruction-following LLaMA-based Model —— 一个中文低资源的llama+lora方案，结构参考alpaca")],-1),re={href:"https://github.com/melodysdreamj/WizardVicunaLM",target:"_blank",rel:"noopener noreferrer"},ie=e("blockquote",null,[e("p",null,"LLM that combines the principles of wizardLM and vicunaLM")],-1),se=e("h2",{id:"other",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#other","aria-hidden":"true"},"#"),n(" Other")],-1),he={href:"https://github.com/THUDM/ChatGLM-6B",target:"_blank",rel:"noopener noreferrer"},ce=e("blockquote",null,[e("p",null,"ChatGLM-6B: An Open Bilingual Dialogue Language Model | 开源双语对话语言模型")],-1),ue={href:"https://github.com/LC1332/Luotuo-Chinese-LLM",target:"_blank",rel:"noopener noreferrer"},pe=e("blockquote",null,[e("p",null,"骆驼(Luotuo): Open Sourced Chinese Language Models")],-1),_e={href:"https://github.com/visual-openllm/visual-openllm",target:"_blank",rel:"noopener noreferrer"},de=e("blockquote",null,[e("p",null,"something like visual-chatgpt, 文心一言的开源版")],-1),fe={href:"https://github.com/wenda-LLM/wenda",target:"_blank",rel:"noopener noreferrer"},ge=e("blockquote",null,[e("p",null,"闻达：一个LLM调用平台。为小模型外挂知识库查找和设计自动执行动作，实现不亚于于大模型的生成能力")],-1),be={href:"https://github.com/CVI-SZU/Linly",target:"_blank",rel:"noopener noreferrer"},me=e("blockquote",null,[e("p",null,"Chinese-LLaMA基础模型；ChatFlow中文对话模型；中文OpenLLaMA模型；NLP预训练/指令微调数据集")],-1),Le={href:"https://github.com/OpenBMB/CPM-Bee",target:"_blank",rel:"noopener noreferrer"},ke=e("blockquote",null,[e("p",null,"百亿参数的中英文双语基座大模型")],-1),Me=e("h2",{id:"tutorial",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#tutorial","aria-hidden":"true"},"#"),n(" Tutorial")],-1),Ae={href:"https://github.com/the-full-stack/website",target:"_blank",rel:"noopener noreferrer"},Ce={href:"https://github.com/imClumsyPanda/langchain-ChatGLM",target:"_blank",rel:"noopener noreferrer"},ye={href:"https://github.com/mymusise/ChatGLM-Tuning",target:"_blank",rel:"noopener noreferrer"},ve={href:"https://zhuanlan.zhihu.com/p/630287397",target:"_blank",rel:"noopener noreferrer"},qe={href:"https://zhuanlan.zhihu.com/p/624012908",target:"_blank",rel:"noopener noreferrer"},Ge={href:"https://zhuanlan.zhihu.com/p/597586623",target:"_blank",rel:"noopener noreferrer"},Pe={href:"https://zhuanlan.zhihu.com/p/54356280",target:"_blank",rel:"noopener noreferrer"},we={href:"https://zhuanlan.zhihu.com/p/54743941",target:"_blank",rel:"noopener noreferrer"};function Te(Ie,ze){const o=a("ExternalLinkIcon");return r(),i("div",null,[h,c,e("ul",null,[e("li",null,[e("a",u,[n("Open LLMs"),t(o)]),p]),e("li",null,[e("a",_,[n("开源大模型食用指南"),t(o)]),d]),e("li",null,[e("a",f,[n("Z-Bench"),t(o)]),g]),e("li",null,[e("a",b,[n("动手学大模型应用开发"),t(o)]),n(" 👉🏻 "),e("a",m,[n("🐙"),t(o)])]),e("li",null,[e("a",L,[n("One API"),t(o)]),k]),e("li",null,[e("a",M,[n("Dify"),t(o)]),n(" 👉🏻 "),e("a",A,[n("🐙"),t(o)]),C])]),y,e("ul",null,[e("li",null,[e("a",v,[n("FastGPT"),t(o)]),n(" 👉🏻 "),e("a",q,[n("🐙"),t(o)]),G]),e("li",null,[e("a",P,[n("GPT4All"),t(o)]),n(" : "),e("a",w,[n("Official"),t(o)]),T]),e("li",null,[e("a",I,[n("minichatgpt"),t(o)]),z]),e("li",null,[e("a",B,[n("privateGPT"),t(o)]),x]),e("li",null,[e("a",V,[n("Code Review GPT"),t(o)]),O])]),F,e("ul",null,[e("li",null,[e("a",N,[n("LLaMA"),t(o)]),n(" : "),e("a",R,[n("introducing"),t(o)]),U]),e("li",null,[e("a",D,[n("llama.cpp"),t(o)]),E]),e("li",null,[e("a",S,[n("ChatLLaMa"),t(o)]),Z]),e("li",null,[e("a",j,[n("pyllama"),t(o)]),K])]),W,e("ul",null,[H,e("li",null,[e("a",Y,[n("alpaca-lora"),t(o)]),J]),e("li",null,[e("a",Q,[n("Chinese-LLaMA-Alpaca"),t(o)]),X]),e("li",null,[e("a",$,[n("KoAlpaca"),t(o)]),ee])]),ne,e("ul",null,[e("li",null,[e("a",oe,[n("FastChat"),t(o)]),te]),e("li",null,[e("a",le,[n("Chinese-Vicuna"),t(o)]),ae]),e("li",null,[e("a",re,[n("WizardVicunaLM"),t(o)]),ie])]),se,e("ul",null,[e("li",null,[e("a",he,[n("ChatGLM-6B"),t(o)]),ce]),e("li",null,[e("a",ue,[n("Luotuo-Chinese-LLM"),t(o)]),pe]),e("li",null,[e("a",_e,[n("Visual OpenLLM"),t(o)]),de]),e("li",null,[e("a",fe,[n("wenda"),t(o)]),ge]),e("li",null,[e("a",be,[n("Linly"),t(o)]),me]),e("li",null,[e("a",Le,[n("CPM-Bee"),t(o)]),ke])]),Me,e("ul",null,[e("li",null,[e("a",Ae,[n("Full Stack LLM Bootcamp"),t(o)])]),e("li",null,[e("a",Ce,[n("基于本地知识库的 ChatGLM 等大语言模型应用实现"),t(o)])]),e("li",null,[e("a",ye,[n("一种平价的chatgpt实现方案, 基于ChatGLM-6B + LoRA"),t(o)])]),e("li",null,[e("a",ve,[n("2023-05-18 GPT大语言模型Vicuna本地化部署实践（效果秒杀Alpaca）"),t(o)])]),e("li",null,[e("a",qe,[n("2023-04-22 大模型也内卷，Vicuna训练及推理指南，效果碾压斯坦福羊驼"),t(o)])]),e("li",null,[e("a",Ge,[n("2023-01-18 通向AGI之路：大型语言模型（LLM）技术精要"),t(o)])]),e("li",null,[e("a",Pe,[n("2019-01-27 BERT大火却不懂Transformer？读这一篇就够了"),t(o)])]),e("li",null,[e("a",we,[n("2019-01-13 放弃幻想，全面拥抱Transformer：自然语言处理三大特征抽取器（CNN/RNN/TF）比较"),t(o)])])])])}const Ve=l(s,[["render",Te],["__file","llms.html.vue"]]);export{Ve as default};
