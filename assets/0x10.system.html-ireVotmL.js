import{_ as e}from"./plugin-vue_export-helper-x3n3nnut.js";import{o as a,c as i,a as d,f as l}from"./app-tfDtes5s.js";const t={},p=l('<hr><h2 id="虚拟内存" tabindex="-1"><a class="header-anchor" href="#虚拟内存" aria-hidden="true">#</a> 虚拟内存</h2><h3 id="❓-虚拟内存-是什么" tabindex="-1"><a class="header-anchor" href="#❓-虚拟内存-是什么" aria-hidden="true">#</a> ❓“虚拟内存”是什么</h3><details class="hint-container details"><summary>💡</summary><blockquote><p><code>Virtual Memory</code> - “虚拟内存”</p></blockquote><p>&quot;虚拟内存&quot;是一种内存管理技术，其被广泛应用在现代计算机操作系统中。</p><p>原本计算机内存空间有限，为了解决程序运行空间不足的问题，虚拟内存技术应运而生。它将内存和磁盘存储器共同作为程序运行的存储空间，从而让系统能够获得更大的可用内存。</p><p>具体来讲，操作系统将内存离散分割为大小固定的页或段，然后创建一个页表或段表来管理它们。这些页或段中的一部分存放在内存中，其他的存放在磁盘上。当程序需要访问的内存页不在内存中（即发生缺页）时，操作系统会从磁盘上调入需要的内存页并换出一些不常用的内存页。这个过程被称为页面调度或页面交换。</p><p>虚拟内存技术使得程序无需关心物理内存的实际大小，而可以利用到远大于物理内存的地址空间，这大大提高了物理内存的使用效率并方便了程序的编写。同时，这也是实现内存保护、多任务系统、分布式系统等现代操作系统功能的基础。</p></details><h3 id="❓一个程序当中的地址是虚拟地址还是物理地址" tabindex="-1"><a class="header-anchor" href="#❓一个程序当中的地址是虚拟地址还是物理地址" aria-hidden="true">#</a> ❓一个程序当中的地址是虚拟地址还是物理地址</h3><details class="hint-container details"><summary>💡</summary><p>在一个程序中，操作系统为其提供的都是虚拟地址，而非物理地址。</p><p>在一个典型的现代计算机系统中，硬件（例如中央处理器）和操作系统之间的交互会使用物理地址，但是你编写的程序实际上并不直接使用物理地址。相反，每一个运行的程序都认为它拥有自己的一段连续的、专有的地址空间，即虚拟地址空间。</p><p>运行一个程序时，该程序看到的每一个内存访问都被操作系统转换为对应的物理内存访问，这中间涉及到虚拟地址到物理地址的映射。这个映射过程是由硬件的内存管理单元（MMU，Memory Management Unit）加上操作系统内核进行管理的。这种处理方式旨在抽象硬件资源，暴露出一个方便编程的接口给程序开发者。</p><p>Virtual Memory（虚拟内存）技术让每个程序都以为自己在使用全部的内存，而实际上物理内存会在许多程序之间动态分配和调度。这个抽象层非常有用，因为它使得每个程序不必考虑共享内存这个问题，它们只需要访问自己的地址空间就好了。</p></details><h3 id="❓得到一个虚拟地址后-怎么转成物理地址" tabindex="-1"><a class="header-anchor" href="#❓得到一个虚拟地址后-怎么转成物理地址" aria-hidden="true">#</a> ❓得到一个虚拟地址后，怎么转成物理地址</h3><details class="hint-container details"><summary>💡</summary><p>虚拟地址到物理地址的转化是通过硬件的内存管理单元（MMU）和由操作系统管理的页表（Page table）完成的。</p><p>在传统的页式内存管理中，虚拟地址被分为两部分：页号（Page Number）和页内偏移（Offset）。页号用于在页表中查找对应的页框号，而页内偏移表示在这个页框中的具体位置。</p><p>具体步骤如下：</p><ol><li><p>通过虚拟地址的页号部分在页表中查找对应的页框号。页表实际上就是一个结构数组，每个元素都包含一个物理页框的相关信息，其中就包括页框号。</p></li><li><p>在找到页框号之后，把它拼接在虚拟地址的页内偏移后面，就得到了完整的物理地址。</p></li></ol><p>这个过程通常是由MMU硬件自动完成的，而操作系统的任务就是在程序运行前设置好页表，并在程序运行过程中根据需要动态更新页表（例如处理缺页异常等）。</p></details><h3 id="❓tlb-了解吗" tabindex="-1"><a class="header-anchor" href="#❓tlb-了解吗" aria-hidden="true">#</a> ❓<code>TLB</code> 了解吗</h3><details class="hint-container details"><summary>💡</summary><blockquote><p>TLB (Translation Lookaside Buffer) 是一个硬件缓存，系统用 <code>TLB</code> 来改进和加速虚拟地址到物理地址的转换过程。</p></blockquote><p>操作系统通常使用一种叫做分页的内存管理技术，把虚拟地址空间和物理地址空间分割成大小相等的块，称为页面。这种页面映射一般会存储在内存中，但每次地址转换都访问这个映射的开销很大，因此 <code>TLB</code> 用于缓存最近使用过的映射，以减少访问内存的次数，加快地址转换速度。</p><p><code>TLB</code> 是一种依赖硬件支持的高速缓存，它提供了从虚拟内存到物理内存的快速转换，使得内存访问更加高效。</p></details><hr><h2 id="页表" tabindex="-1"><a class="header-anchor" href="#页表" aria-hidden="true">#</a> 页表</h2><h3 id="❓行间的换页算法有哪些" tabindex="-1"><a class="header-anchor" href="#❓行间的换页算法有哪些" aria-hidden="true">#</a> ❓行间的换页算法有哪些</h3><details class="hint-container details"><summary>💡</summary><p>&quot;行间的换页算法&quot;应该是指在虚拟内存系统中，当发生缺页中断，即要访问的页面不在内存中时，系统如何替换内存中的页面的策略。常见的换页算法主要有以下几种：</p><ol><li><p>最佳适应算法（Optimal Page Replacement Algorithm）：这种方法是预测未来可能使用到的页面，将在最长时间内不会被访问的页面换出。虽然这种方法理论上可以得到最低的缺页率，但由于无法预知未来的访问模式，因此在实际系统中很难实现。</p></li><li><p>先进先出算法（First-In-First-Out, FIFO）：这种方法很简单，就是将最先调入内存的页面换出。这种方法易于实现，但可能会导致&quot;Belady现象&quot;，即增加内存页面数反而导致缺页率增加。</p></li><li><p>最近未使用算法（Least Recently Used, LRU）：这种方法考虑到程序访问页面的局部性原理，选择最长时间未被访问的页面换出。这种方法获得了很好的效果，但需要操作系统记录页面的访问历史，因此实现起来较为复杂。</p></li><li><p>时钟算法（Clock Algorithm）：时钟算法是对FIFO和LRU的一种折中，通过为每个页面设置一位替换位(R)进行是否需要替换的判断，简化了LRU的操作复杂度，同时也避免了FIFO算法的Belady现象。</p></li></ol><p>以上，就是一些常见的换页算法。在实际的操作系统中可能会根据系统特性和需要使用不同的算法或者独特的变种。</p></details><h3 id="❓页表在-linux-中怎么用的-页式、段式、段页式" tabindex="-1"><a class="header-anchor" href="#❓页表在-linux-中怎么用的-页式、段式、段页式" aria-hidden="true">#</a> ❓页表在 <code>Linux</code> 中怎么用的(页式、段式、段页式)</h3><details class="hint-container details"><summary>💡</summary><p>Linux操作系统使用了虚拟内存技术，页表是其核心组成部分。</p><p>在Linux中，每个运行中的程序（进程）都有一个与其关联的页表，来管理该程序的虚拟地址到物理地址的映射关系。当程序试图访问一个虚拟地址时，硬件的内存管理单元（MMU）会用这个页表来查找对应的物理地址。</p><p>Linux中的页表是一个多级的结构，这样设计的主要目的是为了节省内存。对于一个大的连续地址空间，如果使用单一的线性页表，会导致大量的页表条目浪费。而多级页表可以避免这种情况，只为实际使用到的虚拟地址分配页表条目。</p><p>接下来谈谈页式、段式和段页式这三种内存管理方式：</p><ol><li><p>页式：这种方式下，虚拟空间和物理空间都被等分为大小固定的&quot;页&quot;（例如，1KB或4KB的大小），每个虚拟页可以映射到任意的物理页中。这种方式简单且易于实现，但会产生内部碎片。</p></li><li><p>段式：这种方式下，将程序由含义分割为若干个逻辑的&quot;段&quot;，这些段的大小并不固定，每个段在内存中是连续的。此种方式可以解决内部碎片的问题，但可能产生外部碎片。</p></li><li><p>段页式：是页式与段式的结合。先将程序分割为若干个逻辑上独立的段，然后再将每一段细分为大小固定的页。这种方式需要两个级联的映射表，一个段表用来管理段，一个页表用来管理页。两级映射后，找到的是实际的物理地址。这种方式结合了页式和段式的优点，既能解决内外碎片问题，也符合程序的逻辑性和局部性原则。</p></li></ol><p>Linux和许多现代操作系统采用的是改良的段页式，也就是“多级页表”方法进行内存管理。</p></details><h3 id="❓你是怎么理解页表的" tabindex="-1"><a class="header-anchor" href="#❓你是怎么理解页表的" aria-hidden="true">#</a> ❓你是怎么理解页表的</h3><details class="hint-container details"><summary>💡</summary><p>页表是内存管理中非常重要的一个数据结构，它存储了虚拟地址和物理地址之间的映射关系。</p><p>在操作系统中，每一个正在运行的进程都会有一个相关联的页表。当进程需要访问内存时（实际上进程看到的是虚拟内存），它会给出虚拟地址。这个虚拟地址会通过页表，转换为物理内存地址，然后才能在物理内存中访问到数据或指令。</p><p>页表的实现可能因操作系统而异。比如在一些系统中，页表可能是一个简单的线性数组；在其他系统（比如Linux）中，页表可能是一个多级结构，这样可以节省大量未使用的虚拟地址空间对应的页表空间。</p><p>页表使得操作系统可以更方便地管理物理内存，为每个进程提供了一个连续的虚拟内存空间，而无论物理内存是否连续。此外，页表还可以用来实现内存保护，比如防止一个进程访问另一个进程的内存空间。</p><p>在硬件层面，内存管理单元（MMU）负责使用页表进行虚拟地址到物理地址的转换。页表通常存储在物理内存中，但当前使用的页表地址（即页表基址）会存储在一个特殊的处理器寄存器中。当发生上下文切换（context switch）时，操作系统会更新这个寄存器的值，以切换到新的页表。</p></details><h3 id="❓二级页表是什么" tabindex="-1"><a class="header-anchor" href="#❓二级页表是什么" aria-hidden="true">#</a> ❓二级页表是什么</h3><details class="hint-container details"><summary>💡</summary><p>二级页表是一种内存管理的数据结构，用来将虚拟地址映射到物理地址。其主要目标是解决单级（一级）页表空间占用过大的问题。</p><p>在单级页表中，虚拟地址空间通常被分割成固定大小的页，并为每个页维护一个页表项。因此，如果虚拟地址空间很大而实际使用的内存很小，就会造成大量的页表项浪费。</p><p>为了解决这个问题，可以采用二级页表。在二级页表中，虚拟地址被分为三部分：外层页表索引（也叫页目录索引），内层页表索引（也叫页表索引）和偏移。外层页表（也叫页目录）负责管理所有内层页表，而内层页表则负责管理实际的物理页帧。</p><p>当需要访问一个虚拟地址时，首先使用外层页表索引在页目录中查找对应的内层页表；然后用内层页表索引在该页表中查找对应的物理页帧；最后将找到的页帧地址和原始的偏移拼接起来，就得到了物理地址。</p><p>这样，只有对应虚拟地址实际被使用时，它对应的内层页表才会被创建，未使用的虚拟地址则不会浪费页表项。虽然这种方式增加了地址转换的复杂性，但大大节省了内存空间，所以很多操作系统（如Linux）都采用了这种方式。</p></details><hr><h2 id="cpu" tabindex="-1"><a class="header-anchor" href="#cpu" aria-hidden="true">#</a> CPU</h2><h3 id="❓cpu-是如何调用-gpu" tabindex="-1"><a class="header-anchor" href="#❓cpu-是如何调用-gpu" aria-hidden="true">#</a> ❓<code>CPU</code> 是如何调用 <code>GPU</code></h3><details class="hint-container details"><summary>💡</summary><p>图像的成像原理 : 计算中的图像的展示，需要 <code>CPU</code>、<code>GPU</code> 和显示器合作完成。<code>CPU</code> 负责计算图像哪些数据需要显示，<code>GPU</code> 负责将需要显示的图像数据渲染，然后放入缓存区，显示器读取缓存区数据将图像显示出来。</p><p>CPU通过与其相连的总线系统，向GPU发送指令和数据。这些指令和数据被存储在计算机内存中，由高级软件代码（如OpenGL或DirectX API）组织和发送。当GPU接收到CPU的指令和数据，它会运行相应的图形处理程序或计算任务。</p><p>在具体流程中：</p><ol><li><p>CPU首先将图形数据和操作指令（以特定格式，如OpenGL或DirectX API中的调用）写入内存。这些数据可能包括顶点数据、纹理、渲染指令等。</p></li><li><p>CPU接着通过IO总线（如PCIe）将这些操作指令和数据发送给GPU。</p></li><li><p>GPU接收到这些数据和指令后，将其载入内部的存储器，并开始按指令进行运算操作。</p></li><li><p>运算完后，GPU将结果写回内存，此处内存可能是专门的显存，也可能是与CPU共享的内存。</p></li><li><p>CPU可通过操作系统或GPU驱动程序的接口进行查询，判断GPU是否已经完成任务。如果GPU已经完成任务，CPU可以获取和使用结果数据。</p></li></ol><p>在现代的图形接口中，有一些函数允许CPU和GPU进行数据交流，并控制GPU的行为。此外，许多高级程序设计语言，比如CUDA或OpenCL，允许程序员直接编写在GPU上运行的程序，而不仅仅是传统意义上的图形渲染。</p></details><h3 id="❓cpu-和-gpu-是如何工作-为什么要双缓冲区" tabindex="-1"><a class="header-anchor" href="#❓cpu-和-gpu-是如何工作-为什么要双缓冲区" aria-hidden="true">#</a> ❓<code>CPU</code> 和 <code>GPU</code> 是如何工作，为什么要双缓冲区</h3><details class="hint-container details"><summary>💡</summary><p>首先，让我们了解一下CPU和GPU的基本功能：</p><ol><li><p><strong>CPU（Central Processing Unit）</strong>：CPU是计算机的主处理器，能够执行大部分的运算和逻辑操作。CPU通常负责彼此之间有依赖关系，需要按顺序执行的任务。</p></li><li><p><strong>GPU（Graphics Processing Unit）</strong>：GPU是专门用于处理图形的处理器。GPU通常执行大量并行操作，例如渲染及光线追踪等。</p></li></ol><p>然后，我们再来理解一下双缓冲区：</p><p>双缓冲相当于有两块画布，一块在前台展示，一块在后台绘制。当后台绘制完成后，将后台画布交换到前台，这样就能够确保每次屏幕刷新时，画面都是完整的，从而提高了渲染的效率和质量。</p><p>在CPU和GPU的工作过程中，一种常见的模式是CPU负责准备渲染命令及所有相关的数据（如纹理、顶点数据等），然后将这些数据发送给GPU。再由GPU执行实际的渲染操作——这包括图形的光栅化（把几何图形转换为像素格式）、纹理映射、混合等。</p><p>这就是为什么需要双缓冲区的原因，一块缓冲区用于存储CPU的输出（即GPU的输入），另一块用于存储GPU的输出（即下一帧的图像）。这样的设计让CPU和GPU可以并行工作：当GPU在处理当前帧的渲染时，CPU可以同时准备下一帧的数据。</p></details><hr><h2 id="用户态" tabindex="-1"><a class="header-anchor" href="#用户态" aria-hidden="true">#</a> 用户态</h2><details class="hint-container details"><summary>💡</summary><blockquote><p><code>User Mode</code> - “用户态”</p></blockquote><blockquote><p><code>Kernel Mode</code> - “核心态”</p></blockquote><p>这个区分是一种安全机制，保证了用户程序不能随意访问操作系统核心数据和硬件，保证了操作系统运行的稳定性和安全性。</p><ul><li>在用户态运行的代码不能访问操作系统核心数据结构和硬件，不能执行影响操作系统稳定性的操作。</li><li>核心态运行的代码可以访问操作系统的所有的内存和硬件，大多数操作系统核心程序运行在核心态上，可以执行 CPU 指令，也可以访问所有硬件资源。</li></ul></details><h3 id="❓用户态和内核态-什么时候用户态会转为内核态" tabindex="-1"><a class="header-anchor" href="#❓用户态和内核态-什么时候用户态会转为内核态" aria-hidden="true">#</a> ❓用户态和内核态，什么时候用户态会转为内核态</h3><details class="hint-container details"><summary>💡</summary><p>用户态和内核态是操作系统设计中的两种不同的运行级别，其中内核态具有访问所有硬件资源的权限，而用户态的权限有限，不能直接访问硬件资源。</p><p>通常情况下，所有的用户程序都在用户态运行，只有当需要执行特殊的操作（如I/O操作、权限管理等）时，才需要切换到内核态。特别地，当程序需要请求操作系统服务时，会通过系统调用（Syscall）从用户态切换到内核态。</p><p>例如：</p><ol><li><p>程序要进行文件操作，例如打开文件、读写文件等，因为这些操作需要操作系统访问底层的硬件设备，必须在内核态中完成。用户程序需要进行系统调用切换到内核态，由操作系统代为完成。</p></li><li><p>程序需要进行进程间通信（如管道、消息队列、共享内存等）时，也需要在内核态进行。</p></li><li><p>程序需要进行网络发送或接收操作时，需要系统调用滑动到内核态，由网络协议栈完成数据包的处理。</p></li><li><p>用户程序需要创建、结束进程或进行进程调度时，因为涉及到对进程管理表的操作，也必须在内核态进行。</p></li></ol><p>切换回用户态通常发生在系统调用结束返回时，或者发生了需要切换执行其他用户程序的时候。</p></details><h3 id="❓backtrace-是在用户态实现吗-能否讲讲实现它的大致思路" tabindex="-1"><a class="header-anchor" href="#❓backtrace-是在用户态实现吗-能否讲讲实现它的大致思路" aria-hidden="true">#</a> ❓<code>backtrace</code> 是在用户态实现吗？能否讲讲实现它的大致思路</h3><details class="hint-container details"><summary>💡</summary><p>先理解两个概念 : <code>backtrace</code>、用户态</p><ul><li><code>backtrace</code> 是回溯栈，记录程序运行过程中的调用栈信息，当程序 <code>Crash</code> 时，可以通过这个信息了解程序崩溃的上下文，调试程序问题。</li><li>用户态是属于操作系统的一个分区概念，主要分为内核态和用户态。两者的区别的是为了保证内核安全，只有以内核态运行的程序才具备操作系统所有资源的访问权限，而以用户态运行的程序会受到限制，这样是为了保证操作系统的稳定运行。</li></ul><p><code>backtrace</code>一般是在用户态实现的，主要是通过读取和解析程序的调用栈来获取函数的调用历史。</p><p>这里是一个简化的实现过程：</p><ol><li><p>获取栈顶地址：首先，我们需要获取当前函数的栈顶地址，这可以通过内联汇编或者某些特定的函数实现，例如<code>__builtin_frame_address</code>。</p></li><li><p>遍历栈帧：然后，我们从栈顶开始，获得每一个栈帧的返回地址，并按照栈的生长方向（通常是向低地址方向），逐个获取下一个栈帧的返回地址。这个过程一直持续到遇到一个无效的栈帧地址为止。</p></li><li><p>解析函数名：有了函数的返回地址，我们就可以通过解析程序的符号表，找到这个地址所对应的函数名。在Linux中，可以使用<code>backtrace_symbols</code>函数帮助我们完成这个任务。</p></li><li><p>输出结果：最后，我们将每一个栈帧对应的函数名输出，就得到了函数的调用栈。</p></li></ol><p>需要注意的是，上述过程在实际操作中可能要复杂得多，因为现代的编译器可能会对程序进行各种优化，例如函数内联、尾递归优化等，这些都可能影响到我们获取调用栈的结果，因此在使用<code>backtrace</code>的时候，可能需要关闭这些编译器优化。</p></details>',33);function r(c,s){return a(),i("div",null,[d(" more "),p])}const h=e(t,[["render",r],["__file","0x10.system.html.vue"]]);export{h as default};
