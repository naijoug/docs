import{_ as e}from"./plugin-vue_export-helper-x3n3nnut.js";import{o,c,a as d,f as a}from"./app-bI98unat.js";const t={},l=a('<blockquote><p><code>GPUImage</code> 框架介绍</p></blockquote><blockquote><p><code>OpenGL</code> 处理流程</p></blockquote><blockquote><p>直播整体流程</p></blockquote><blockquote><p>视频从<code>采集 -&gt; 显示 -&gt; 保存</code> 整个流程</p></blockquote><blockquote><p>视频如何两倍速播放，并二倍速导出</p></blockquote><blockquote><p>大图加载</p></blockquote><blockquote><p><code>PCM</code> 计算时间</p></blockquote><blockquote><p>音频降燥、视频合成</p></blockquote><h2 id="编码" tabindex="-1"><a class="header-anchor" href="#编码" aria-hidden="true">#</a> 编码</h2><blockquote><p>硬编码 vs 软编码</p></blockquote><blockquote><p>FBO、H264</p></blockquote><h2 id="滤镜" tabindex="-1"><a class="header-anchor" href="#滤镜" aria-hidden="true">#</a> 滤镜</h2><blockquote><p>实现原理</p></blockquote><blockquote><p>如何实现分割滤镜？</p></blockquote><h2 id="直播" tabindex="-1"><a class="header-anchor" href="#直播" aria-hidden="true">#</a> 直播</h2><blockquote><p><code>rtmp</code>、<code>webrtc</code></p></blockquote><blockquote><p><code>ffmpeg</code></p></blockquote><blockquote><p><code>OpenCV</code></p></blockquote><h2 id="avfoundation" tabindex="-1"><a class="header-anchor" href="#avfoundation" aria-hidden="true">#</a> <code>AVFoundation</code></h2><blockquote><p><code>AVFoundation</code> &amp; <code>GPUImage</code> &amp; <code>OpenGL ES</code> &amp; <code>MetalKit</code></p></blockquote><h3 id="samplebuffer-与-pixelbuffer-区别" tabindex="-1"><a class="header-anchor" href="#samplebuffer-与-pixelbuffer-区别" aria-hidden="true">#</a> <code>samplebuffer</code> 与 <code>pixelbuffer</code> 区别</h3><details class="hint-container details"><summary>💡</summary><ul><li><p><code>CMSampleBufferRef</code> : <code>Core Media</code>框架中被用来管理音频、视频、字幕等样本的集合。一个 <code>samplebuffer</code> 包含一到多个样本以及描述这些样本的元数据，例如显示时间戳、解码时间戳、持续时间、帧速率等。<code>samplebuffer</code>在更高的层级管理数据，包含了解压缩和播放媒体所需的所有信息。</p></li><li><p><code>CVPixelBufferRef</code> : <code>Core Video</code> 框架中被用来管理图像数据。一个 <code>pixelbuffer</code> 表示一个视频帧，它包含了视频帧的原始像素数据。<code>pixelbuffer</code> 是在更低的层级处理数据，仅仅包含了像素信息，没有时间戳、持续时间等元数据。</p></li></ul><blockquote><p>两者区别：<code>samplebuffer</code> 是对包含音频、视频、字幕等样本的集合的封装，包含了播放媒体所需的所有信息，<code>pixelbuffer</code> 是对视频帧的原始像素数据的封装，更关注图像层面的细节。</p></blockquote></details><blockquote><p><code>CMTime</code> 结构</p></blockquote><blockquote><p>如何使用 <code>AVFoundation</code> 给视频添加水印？</p></blockquote><h2 id="avplayer" tabindex="-1"><a class="header-anchor" href="#avplayer" aria-hidden="true">#</a> <code>AVPlayer</code></h2><blockquote><p>实现原理</p></blockquote><blockquote><p>缓存机制</p></blockquote><blockquote><p>边播边下</p></blockquote><h2 id="设计一个通用视频播放器" tabindex="-1"><a class="header-anchor" href="#设计一个通用视频播放器" aria-hidden="true">#</a> 设计一个通用视频播放器</h2>',29);function u(p,r){return o(),c("div",null,[d(" more "),l])}const f=e(t,[["render",u],["__file","media.html.vue"]]);export{f as default};
