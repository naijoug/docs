import{_ as l}from"./plugin-vue_export-helper-x3n3nnut.js";import{r,o as a,c as s,b as e,e as n,d as t}from"./app-pRGiPbnF.js";const i={},h=e("blockquote",null,[e("p",null,[e("code",null,"LLMs"),n("("),e("code",null,"Large Language Models"),n(") : å¤§è¯­è¨€æ¨¡å‹")])],-1),c=e("h2",{id:"reference",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#reference","aria-hidden":"true"},"#"),n(" reference")],-1),u={href:"https://github.com/eugeneyan/open-llms",target:"_blank",rel:"noopener noreferrer"},p=e("blockquote",null,[e("p",null,"ğŸ¤– A list of open LLMs available for commercial use.")],-1),_={href:"https://openrouter.ai/rankings",target:"_blank",rel:"noopener noreferrer"},d={href:"https://github.com/datawhalechina/self-llm",target:"_blank",rel:"noopener noreferrer"},f=e("blockquote",null,[e("p",null,"ã€Šå¼€æºå¤§æ¨¡å‹é£Ÿç”¨æŒ‡å—ã€‹åŸºäºLinuxç¯å¢ƒå¿«é€Ÿéƒ¨ç½²å¼€æºå¤§æ¨¡å‹ï¼Œæ›´é€‚åˆä¸­å›½å®å®çš„éƒ¨ç½²æ•™ç¨‹")],-1),b={href:"https://github.com/zhenbench/z-bench",target:"_blank",rel:"noopener noreferrer"},g=e("blockquote",null,[e("p",null,"Z-Bench 1.0 by çœŸæ ¼åŸºé‡‘ï¼šä¸€ä¸ªéº»ç“œçš„å¤§è¯­è¨€æ¨¡å‹ä¸­æ–‡æµ‹è¯•é›†ã€‚Z-Bench is a LLM prompt dataset for non-technical users, developed by an enthusiastic AI-focused team in Zhenfund")],-1),m={href:"https://aitutor.liduos.com/",target:"_blank",rel:"noopener noreferrer"},L={href:"https://github.com/morsoli/llm-books",target:"_blank",rel:"noopener noreferrer"},k=e("blockquote",null,[e("p",null,"åˆ©ç”¨ LLM æ„å»ºåº”ç”¨å®è·µç¬”è®°")],-1),M={href:"https://datawhalechina.github.io/llm-universe/#/",target:"_blank",rel:"noopener noreferrer"},A={href:"https://github.com/datawhalechina/llm-universe",target:"_blank",rel:"noopener noreferrer"},C={href:"https://dify.ai",target:"_blank",rel:"noopener noreferrer"},y={href:"https://github.com/langgenius/dify",target:"_blank",rel:"noopener noreferrer"},v=e("blockquote",null,[e("p",null,"Dify is an open-source LLM app development platform. Dify's intuitive interface combines AI workflow, RAG pipeline, agent capabilities, model management, observability features and more, letting you quickly go from prototype to production.")],-1),q=e("h2",{id:"gpt",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#gpt","aria-hidden":"true"},"#"),n(" GPT")],-1),G={href:"https://fastgpt.in",target:"_blank",rel:"noopener noreferrer"},w={href:"https://github.com/labring/FastGPT",target:"_blank",rel:"noopener noreferrer"},T=e("blockquote",null,[e("p",null,"FastGPT is a knowledge-based platform built on the LLMs, offers a comprehensive suite of out-of-the-box capabilities such as data processing, RAG retrieval, and visual AI workflow orchestration, letting you easily develop and deploy complex question-answering systems without the need for extensive setup or configuration.")],-1),P={href:"https://github.com/nomic-ai/gpt4all",target:"_blank",rel:"noopener noreferrer"},B={href:"https://gpt4all.io",target:"_blank",rel:"noopener noreferrer"},x=e("blockquote",null,[e("p",null,"gpt4all: an ecosystem of open-source chatbots trained on a massive collections of clean assistant data including code, stories and dialogue")],-1),z={href:"https://github.com/juncongmoo/minichatgpt",target:"_blank",rel:"noopener noreferrer"},I=e("blockquote",null,[e("p",null,"ğŸ”¥ To Train ChatGPT In 5 Minutes with ColossalAI")],-1),V={href:"https://github.com/imartinez/privateGPT",target:"_blank",rel:"noopener noreferrer"},F=e("blockquote",null,[e("p",null,"Interact privately with your documents using the power of GPT, 100% privately, no data leaks")],-1),O={href:"https://github.com/mattzcarey/code-review-gpt",target:"_blank",rel:"noopener noreferrer"},R=e("blockquote",null,[e("p",null,"Your personal code reviewer powered by LLMs (OpenAI GPT-3.5/4, Llama, Falcon, Azure AI) & Embeddings âš¡ï¸ Improve code quality and catch bugs before you break production ğŸš€")],-1),N=e("h2",{id:"llama",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#llama","aria-hidden":"true"},"#"),n(" LLaMa")],-1),S={href:"https://github.com/facebookresearch/llama",target:"_blank",rel:"noopener noreferrer"},D={href:"https://ai.facebook.com/blog/large-language-model-llama-meta-ai/",target:"_blank",rel:"noopener noreferrer"},U=e("blockquote",null,[e("p",null,"Inference code for LLaMA models")],-1),E={href:"https://github.com/ggerganov/llama.cpp",target:"_blank",rel:"noopener noreferrer"},Z=e("blockquote",null,[e("p",null,"Port of Facebook's LLaMA model in C/C++")],-1),j={href:"https://github.com/juncongmoo/chatllama",target:"_blank",rel:"noopener noreferrer"},K=e("blockquote",null,[e("p",null,"ChatLLaMA ğŸ“¢ Open source implementation for LLaMA-based ChatGPT runnable in a single GPU. 15x faster training process than ChatGPT")],-1),W={href:"https://github.com/juncongmoo/pyllama",target:"_blank",rel:"noopener noreferrer"},H=e("blockquote",null,[e("p",null,"ğŸ¦™ LLaMA - Run LLM in A Single 4GB GPU")],-1),Y=e("h2",{id:"alpaca",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#alpaca","aria-hidden":"true"},"#"),n(" Alpaca")],-1),J=e("li",null,[e("a",{href:"https//github.com/tatsu-lab/stanford_alpaca"},"Stanford Alpaca"),e("blockquote",null,[e("p",null,"An Instruction-following LLaMA Model")])],-1),Q={href:"https://github.com/tloen/alpaca-lora",target:"_blank",rel:"noopener noreferrer"},X=e("blockquote",null,[e("p",null,"Instruct-tune LLaMA on consumer hardware")],-1),$={href:"https://github.com/ymcui/Chinese-LLaMA-Alpaca",target:"_blank",rel:"noopener noreferrer"},ee=e("blockquote",null,[e("p",null,"ä¸­æ–‡LLaMA&Alpacaå¤§è¯­è¨€æ¨¡å‹+æœ¬åœ°CPU/GPUéƒ¨ç½² (Chinese LLaMA & Alpaca LLMs)")],-1),ne={href:"https://github.com/Beomi/KoAlpaca",target:"_blank",rel:"noopener noreferrer"},oe=e("blockquote",null,[e("p",null,"KoAlpaca: Korean Alpaca Model based on Stanford Alpaca (feat. LLAMA and Polyglot-ko)")],-1),te=e("h2",{id:"vicuna",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#vicuna","aria-hidden":"true"},"#"),n(" Vicuna")],-1),le={href:"https://github.com/lm-sys/FastChat",target:"_blank",rel:"noopener noreferrer"},re=e("blockquote",null,[e("p",null,"An open platform for training, serving, and evaluating large language models. Release repo for Vicuna and FastChat-T5.")],-1),ae={href:"https://github.com/Facico/Chinese-Vicuna",target:"_blank",rel:"noopener noreferrer"},se=e("blockquote",null,[e("p",null,"Chinese-Vicuna: A Chinese Instruction-following LLaMA-based Model â€”â€” ä¸€ä¸ªä¸­æ–‡ä½èµ„æºçš„llama+loraæ–¹æ¡ˆï¼Œç»“æ„å‚è€ƒalpaca")],-1),ie={href:"https://github.com/melodysdreamj/WizardVicunaLM",target:"_blank",rel:"noopener noreferrer"},he=e("blockquote",null,[e("p",null,"LLM that combines the principles of wizardLM and vicunaLM")],-1),ce=e("h2",{id:"other",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#other","aria-hidden":"true"},"#"),n(" Other")],-1),ue={href:"https://github.com/deepseek-ai/DeepSeek-V3",target:"_blank",rel:"noopener noreferrer"},pe={href:"https://github.com/THUDM/ChatGLM-6B",target:"_blank",rel:"noopener noreferrer"},_e=e("blockquote",null,[e("p",null,"ChatGLM-6B: An Open Bilingual Dialogue Language Model | å¼€æºåŒè¯­å¯¹è¯è¯­è¨€æ¨¡å‹")],-1),de={href:"https://github.com/LC1332/Luotuo-Chinese-LLM",target:"_blank",rel:"noopener noreferrer"},fe=e("blockquote",null,[e("p",null,"éª†é©¼(Luotuo): Open Sourced Chinese Language Models")],-1),be={href:"https://github.com/visual-openllm/visual-openllm",target:"_blank",rel:"noopener noreferrer"},ge=e("blockquote",null,[e("p",null,"something like visual-chatgpt, æ–‡å¿ƒä¸€è¨€çš„å¼€æºç‰ˆ")],-1),me={href:"https://github.com/wenda-LLM/wenda",target:"_blank",rel:"noopener noreferrer"},Le=e("blockquote",null,[e("p",null,"é—»è¾¾ï¼šä¸€ä¸ªLLMè°ƒç”¨å¹³å°ã€‚ä¸ºå°æ¨¡å‹å¤–æŒ‚çŸ¥è¯†åº“æŸ¥æ‰¾å’Œè®¾è®¡è‡ªåŠ¨æ‰§è¡ŒåŠ¨ä½œï¼Œå®ç°ä¸äºšäºäºå¤§æ¨¡å‹çš„ç”Ÿæˆèƒ½åŠ›")],-1),ke={href:"https://github.com/CVI-SZU/Linly",target:"_blank",rel:"noopener noreferrer"},Me=e("blockquote",null,[e("p",null,"Chinese-LLaMAåŸºç¡€æ¨¡å‹ï¼›ChatFlowä¸­æ–‡å¯¹è¯æ¨¡å‹ï¼›ä¸­æ–‡OpenLLaMAæ¨¡å‹ï¼›NLPé¢„è®­ç»ƒ/æŒ‡ä»¤å¾®è°ƒæ•°æ®é›†")],-1),Ae={href:"https://github.com/OpenBMB/CPM-Bee",target:"_blank",rel:"noopener noreferrer"},Ce=e("blockquote",null,[e("p",null,"ç™¾äº¿å‚æ•°çš„ä¸­è‹±æ–‡åŒè¯­åŸºåº§å¤§æ¨¡å‹")],-1),ye=e("h2",{id:"tutorial",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#tutorial","aria-hidden":"true"},"#"),n(" Tutorial")],-1),ve={href:"https://github.com/the-full-stack/website",target:"_blank",rel:"noopener noreferrer"},qe={href:"https://github.com/imClumsyPanda/langchain-ChatGLM",target:"_blank",rel:"noopener noreferrer"},Ge={href:"https://github.com/mymusise/ChatGLM-Tuning",target:"_blank",rel:"noopener noreferrer"},we={href:"https://zhuanlan.zhihu.com/p/630287397",target:"_blank",rel:"noopener noreferrer"},Te={href:"https://zhuanlan.zhihu.com/p/624012908",target:"_blank",rel:"noopener noreferrer"},Pe={href:"https://zhuanlan.zhihu.com/p/597586623",target:"_blank",rel:"noopener noreferrer"},Be={href:"https://zhuanlan.zhihu.com/p/54356280",target:"_blank",rel:"noopener noreferrer"},xe={href:"https://zhuanlan.zhihu.com/p/54743941",target:"_blank",rel:"noopener noreferrer"};function ze(Ie,Ve){const o=r("ExternalLinkIcon");return a(),s("div",null,[h,c,e("ul",null,[e("li",null,[e("a",u,[n("Open LLMs"),t(o)]),p]),e("li",null,[e("a",_,[n("LLM Rankings"),t(o)])]),e("li",null,[e("a",d,[n("å¼€æºå¤§æ¨¡å‹é£Ÿç”¨æŒ‡å—"),t(o)]),f]),e("li",null,[e("a",b,[n("Z-Bench"),t(o)]),g]),e("li",null,[e("a",m,[n("llm-books"),t(o)]),n(" ğŸ‘‰ğŸ» "),e("a",L,[n("ğŸ™"),t(o)]),k]),e("li",null,[e("a",M,[n("åŠ¨æ‰‹å­¦å¤§æ¨¡å‹åº”ç”¨å¼€å‘"),t(o)]),n(" ğŸ‘‰ğŸ» "),e("a",A,[n("ğŸ™"),t(o)])]),e("li",null,[e("a",C,[n("Dify"),t(o)]),n(" ğŸ‘‰ğŸ» "),e("a",y,[n("ğŸ™"),t(o)]),v])]),q,e("ul",null,[e("li",null,[e("a",G,[n("FastGPT"),t(o)]),n(" ğŸ‘‰ğŸ» "),e("a",w,[n("ğŸ™"),t(o)]),T]),e("li",null,[e("a",P,[n("GPT4All"),t(o)]),n(" : "),e("a",B,[n("Official"),t(o)]),x]),e("li",null,[e("a",z,[n("minichatgpt"),t(o)]),I]),e("li",null,[e("a",V,[n("privateGPT"),t(o)]),F]),e("li",null,[e("a",O,[n("Code Review GPT"),t(o)]),R])]),N,e("ul",null,[e("li",null,[e("a",S,[n("LLaMA"),t(o)]),n(" : "),e("a",D,[n("introducing"),t(o)]),U]),e("li",null,[e("a",E,[n("llama.cpp"),t(o)]),Z]),e("li",null,[e("a",j,[n("ChatLLaMa"),t(o)]),K]),e("li",null,[e("a",W,[n("pyllama"),t(o)]),H])]),Y,e("ul",null,[J,e("li",null,[e("a",Q,[n("alpaca-lora"),t(o)]),X]),e("li",null,[e("a",$,[n("Chinese-LLaMA-Alpaca"),t(o)]),ee]),e("li",null,[e("a",ne,[n("KoAlpaca"),t(o)]),oe])]),te,e("ul",null,[e("li",null,[e("a",le,[n("FastChat"),t(o)]),re]),e("li",null,[e("a",ae,[n("Chinese-Vicuna"),t(o)]),se]),e("li",null,[e("a",ie,[n("WizardVicunaLM"),t(o)]),he])]),ce,e("ul",null,[e("li",null,[e("a",ue,[n("DeepSeek-V3"),t(o)])]),e("li",null,[e("a",pe,[n("ChatGLM-6B"),t(o)]),_e]),e("li",null,[e("a",de,[n("Luotuo-Chinese-LLM"),t(o)]),fe]),e("li",null,[e("a",be,[n("Visual OpenLLM"),t(o)]),ge]),e("li",null,[e("a",me,[n("wenda"),t(o)]),Le]),e("li",null,[e("a",ke,[n("Linly"),t(o)]),Me]),e("li",null,[e("a",Ae,[n("CPM-Bee"),t(o)]),Ce])]),ye,e("ul",null,[e("li",null,[e("a",ve,[n("Full Stack LLM Bootcamp"),t(o)])]),e("li",null,[e("a",qe,[n("åŸºäºæœ¬åœ°çŸ¥è¯†åº“çš„ ChatGLM ç­‰å¤§è¯­è¨€æ¨¡å‹åº”ç”¨å®ç°"),t(o)])]),e("li",null,[e("a",Ge,[n("ä¸€ç§å¹³ä»·çš„chatgptå®ç°æ–¹æ¡ˆ, åŸºäºChatGLM-6B + LoRA"),t(o)])]),e("li",null,[e("a",we,[n("2023-05-18 GPTå¤§è¯­è¨€æ¨¡å‹Vicunaæœ¬åœ°åŒ–éƒ¨ç½²å®è·µï¼ˆæ•ˆæœç§’æ€Alpacaï¼‰"),t(o)])]),e("li",null,[e("a",Te,[n("2023-04-22 å¤§æ¨¡å‹ä¹Ÿå†…å·ï¼ŒVicunaè®­ç»ƒåŠæ¨ç†æŒ‡å—ï¼Œæ•ˆæœç¢¾å‹æ–¯å¦ç¦ç¾Šé©¼"),t(o)])]),e("li",null,[e("a",Pe,[n("2023-01-18 é€šå‘AGIä¹‹è·¯ï¼šå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æŠ€æœ¯ç²¾è¦"),t(o)])]),e("li",null,[e("a",Be,[n("2019-01-27 BERTå¤§ç«å´ä¸æ‡‚Transformerï¼Ÿè¯»è¿™ä¸€ç¯‡å°±å¤Ÿäº†"),t(o)])]),e("li",null,[e("a",xe,[n("2019-01-13 æ”¾å¼ƒå¹»æƒ³ï¼Œå…¨é¢æ‹¥æŠ±Transformerï¼šè‡ªç„¶è¯­è¨€å¤„ç†ä¸‰å¤§ç‰¹å¾æŠ½å–å™¨ï¼ˆCNN/RNN/TFï¼‰æ¯”è¾ƒ"),t(o)])])])])}const Re=l(i,[["render",ze],["__file","llms.html.vue"]]);export{Re as default};
