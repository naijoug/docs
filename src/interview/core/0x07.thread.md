---
title: thread - “多线程”
icon: hashtag

index: true

---

<!-- more -->

------

## 概念知识

### ❓说说你理解的多线程

::: details 💡

多线程是指程序中包含两个或者更多个可以同时运行的部分，这两个或者多个部分互相独立但又共享某些资源，可以并行执行的每个独立的运行部分就是一个线程。

每个线程都有它自己的程序计数器、一组寄存器和堆栈，这些都是线程从被暂停到再次被执行所必需的，而尽管每个线程都有自己的堆栈，但是该线程所对应的进程的所有线程都共享同样的地址空间，它们就像是属于同一个进程下的兄弟。

多线程的主要优点有：

1. 充分利用多核处理器的计算能力，一台多核 CPU 计算机上的多线程程序可以使用更多的核，从而提高程序的性能。

2. 提高程序的响应速度，用户界面的多线程设计可以保证用户界面始终对用户的操作做出响应，并且可以做到许多耗时的操作和用户界面的独立处理。

3. 简化复杂的程序设计。一些需要同时处理多个用户请求或者需要连续完成处理一系列任务的软件，使用多线程可以很好地解耦和简化程序设计，提高程序设计的效率。

然而，多线程也会带来一系列的问题：

1. 线程并发执行时可能需要访问同一块资源（如全局变量），这就会带来同步和互斥问题，例如经典的生产者消费者问题，读者写者问题等。

2. 多线程技术需要操作系统的支持，不是所有的操作系统或者编程语言都适合编写多线程程序。多线程编程通常需要一些复杂的技巧和细心的设计。

3. 多线程程序的调试和测试比单线程的程序更为困难，因为由于线程是并发执行的，每个线程都有自己独立的上下文，导致线程的执行顺序无法预测。

:::

### ❓并行 vs 串行

::: details 💡

  并行 (Concurrency) : 多个任务会同时执行。如果是多核 CPU 会是真正意义上并行，多个任务会在不同 CPU 上同时运行；如果是单核 CPU 是一种伪并行，是同一时间间隔上运行多个任务，CPU 在多个任务上切换运行，其实某一时刻上其实只有一个任务执行，由于 CPU 运行速度比较快，用户角度观察呈现并发状态。

1. 并行和串行是两种不同的处理方式，下面是对它们的基本理解和区别：

并行处理：
- 并行处理是指两个或更多任务（或进程）在同一时刻进行，也就是说它们是同时执行的。比如，超市的几个结账通道就可以同时服务多个顾客，这就是一个并行的例子。

串行处理：
- 串行处理是指在一段时间段内同一时间点只处理一个任务或进程。在任务一完成之后任务二才可以开始等等，比如一个人在超市逐个挑选商品，从牛奶到面包再到鸡蛋，这个过程就是串行的。

2. 并行和串行的主要区别包括：
- 并行处理可以大大提高处理速度和工作效率，因为多个任务可以同时进行。然而，并行处理需要硬件和软件具有支持并行执行的能力，并且编程和管理起来比较复杂。
- 串行处理更容易理解和实现。任务一个接一个地执行，不需要协调多任务的执行顺序和结果合并等。然而，所有任务的总执行时间是各个任务执行时间的总和，执行效率比较低。

并行和串行不是好坏之分，而是依据实际情况选择。

:::

### ❓进程 vs 线程 vs 协程

::: details 💡

  - 进程(Process) : 程序的一次运行活动，各个进程之间相互资源独立。操作系统分配资源的基本单位，具有唯一的 PID 和 port 号。
  - 线程(Thread) : 线程是进程的最小执行单位，同一个进程内的多个线程共享进程内的资源。
  - 协程(Coroutine) : 也被称为“微线程”。运行在用户态，相比于线程具有极高的执行效率和极低的切换成本。

进程、线程、协程都是程序执行流的基本单元，但它们有着明显的区别：

1. 进程：
   - 进程是操作系统资源分配的基本单元，是一个运行中的程序的实例。
   - 进程具有自己独立的内存空间和系统资源。各个进程间的资源不共享，相互隔离，一个进程不能访问另一个进程的资源和内存空间。
   - 进程间的通信(IPC)方式复杂，如管道、信号、消息队列、共享内存、套接字等。

2. 线程：
   - 线程是操作系统任务调度的基本单元，进程内一个相对独立的、可调度的执行单元。同属一个进程的多个线程共享进程的资源。
   - 线程的切换开销小于进程，因为同一个进程下的线程共享内存和资源，状态切换相对简单。
   - 线程间通常可以直接通信，通信开销小。

3. 协程：
   - 协程是一种用户态的轻量级线程，也叫微线程，是程序员显式进行调度的，非抢卢，对操作系统透明。
   - 协程的切换不涉及系统调用，开销极小。
   - 协程允许有多个入口点，可以在任何地方暂停执行，并在必要时恢复执行，增强了程序的灵活性。

总结，进程、线程和协程，从上到下执行效率越来越高（开销越来越小），但管理和编程复杂度也相应提高。再者，这三者并无优劣之分，具体使用哪个需要根据实际情况和需求来判断。

:::

### ❓进程间如何通信

::: details 💡

  操作系统为支持进程间通信（Inter-Process Communication，IPC）提供了多种机制。以下是一些常见的IPC方法：

1. 管道（Pipe）：管道是最古老的进程间通信方式，它可用于具有血缘关系的父子进程之间通信。数据在管道中只能从一端流入，从另一端流出，即单向流动。

2. 命名管道（Named Pipe）：命名管道也叫FIFO，它是管道的延伸和发展，可用于互不相关的进程间通信。

3. 信号（Signals）：信号是一种非常复杂的通信方式，用于通知接收进程某个事件已经发生。

4. 消息队列（Message Queue）：消息队列是由消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息量小，管道只能承载无格式字节流以及缓冲区大小受限等缺点。

5. 信号量（Semaphore）：信号量主要作为进程间以及同一进程不同线程之间的同步手段。

6. 共享内存（Shared Memory）：共享内存就是映射一段能被其他进程所访问的内存，适用于大量数据的读写。因为数据不需要在进程间来回复制，效率很高。

7. 套接字（Socket）：套接字可以用于不同机器之间的进程通信。使用最广泛的IPC方式。

8. 内存映射（Memory Mapping）：类似于共享内存，允许不同进程访问同一段物理内存。应用于大数据的处理和文件的读写。

以上各种IPC方式各有优劣，需要根据具体的应用场景来选择使用哪种通信方式。

:::

### ❓进程 A 和进程 B 通过管道通信的话是在同一个管道吗

::: details 💡

管道（Pipe）是半双工的，数据只能向一个方向流动。也就是说，如果进程A需要发送数据给进程B，同时进程B又需要发送数据给进程A，那么就需要创建两个管道，一个管道用于A到B的通信，另一个管道用于B到A的通信。

因此，如果进程A和进程B需要进行双向的数据传输，那么是需要两个管道的，一个用于A发送数据至B，另一个用于B发送数据至A。

:::

### ❓线程间的通信方式

::: details 💡

线程间的通信方式主要依赖于它们共享的数据结构、变量等资源，常用的线程间通信方式包括：

1. 锁机制：提供了保护共享数据访问的方式，用于控制哪个线程可以访问共享数据。

2. 信号量：主要用于同步线程的执行顺序，例如有两个线程，一个线程完成一项任务后，另一个线程才能开始任务，那么就需要用到信号量。

3. 条件变量：用于等待条件的满足以便继续执行。例如有两个线程，一个生产者线程和一个消费者线程，消费者线程可能需要等待生产者生产出产品后才能继续执行，那么就需要用到条件变量。

4. 互斥锁（Mutex）：用于保护共享资源，确保同一时间只有一个线程可以访问这个资源。

5. 事件：线程可以调用事件API来设置或者等待某个事件的发生，从而实现线程间的通信。

6. 共享内存：线程间也可以通过共享内存来通信，同一进程的所有线程都共享该进程的全局内存，所以线程之间可以方便地访问相同的数据。

不同的通信方式适用于不同的场景，具体使用哪种方式取决于具体的应用需求。

:::

### ❓最多能开辟多少个进程和线程

::: details 💡

进程和线程的数量是由操作系统的限制以及系统的硬件资源（如CPU、RAM等）决定的。

对于进程，Linux系统中可以使用命令 ulimit -u 来查看用户进程限制的数量。默认情况下，这个数量可能是1024，或者更高。你也可以通过修改系统配置来修改这个数量。但请注意，进程数量的上限还受到系统的其他资源限制，比如可用的内存。

对于线程，每个进程中可以创建的线程数量是由系统的内存大小和堆栈大小共同决定的。线程数量的上限也可以通过 ulimit -u 命令查看。在64位Linux系统中，每个进程最多可以创建几百万个线程，这个数量远远高于常见的服务器所需。

总的来说，虽然理论上进程和线程的数量可能很大，但在实践中，因为需要考虑系统的性能和稳定性，通常我们会尽量减少进程和线程的数量，使用像线程池这样的方式来提高资源利用率。

:::

### ❓说说编程语言都开始支持的 `async/await`

::: details 💡

async/await是现今很多编程语言支持的一种特性。这两个关键词能够使异步操作（比如文件读取、网络请求、定时操作等）更像是同步操作，有助于简化代码逻辑和提高代码可读性。

目前支持这种特性的语言包括：
1. JavaScript - 在ES7规范中引入，现今主流的JS运行环境如浏览器和Node.js均已支持
2. Python - 在3.5版本中新增，内置了对异步IO的支持
3. TypeScript - 微软开发的JavaScript的超集语言，支持async/await，并可以编译到ES5/ES3等不支持这个特性的JS版本上运行
4. C# - 在5.0版本中引入，主要用于异步IO操作和task的等待
5. Dart - Google开发的一种语言，用于Flutter框架开发，支持async/await，提升开发效率
6. Rust - 新兴的系统编程语言，从1.39版本开始对async/await提供稳定支持。

async/await的基本操作原理是：async用于声明一个函数为异步函数，异步函数内部可以使用await关键词来等待一个异步操作返回。async函数返回的结果是一个Promise对象（或者类似的Future对象），这个对象表示的是一个尚未完成的异步操作。

使用async/await编程模型，可以使得原本需要使用回调（Callback）或者Promise来处理的异步结果，能够以同步的方式来编写和读取，大大简化了异步编程的难度，提高代码的可读性和可维护性。

:::

------

## 线程安全

### ❓什么是线程安全

::: details 💡

线程安全是多线程环境下，当多个线程访问某一个对象或程序时，不会对程序的执行和对象所产生的影响进行破坏，始终表现出正确的行为，我们就称这段代码是线程安全的。

举个例子，考虑一个程序其运行环境有多个线程，这个程序会被多个线程共享并进行写操作，如果每次运行结果和我们预期的一样，那么就是线程安全的。反之，所谓的非线程安全就是程序的运行结果会受到多线程的影响。

线程不安全的情况通常发生在全局变量和静态变量的场景中，多个线程同时修改一个实例变量的时候，会产生并发问题，如果不采取适当的防护措施，比如互斥锁、信号量、程序上锁等方法去防范，就可能导致程序运行错误。

编写线程安全的代码需要仔细设计，考虑好各项竞态条件以及可能的并发问题。

:::

### ❓线程死锁的四个条件

::: details 💡

死锁是多个线程永久性地阻塞，无法继续执行的状态。这经常发生在每个线程都在等待其他线程释放它们需要的资源，而这个资源又正被等待释放它的线程持有。

死锁通常需要以下四个必要条件共同存在：
1. 互斥条件：一个资源每次只能被一个线程使用，即在一段时间内某资源只为一个线程所占有，此时若有其他线程请求该资源，则请求者只能等待。
2. 请求和保持条件：一个线程因请求占有其他资源而阻塞时，对已获得的资源保持不放。
3. 不剥夺条件：线程已经获得的资源，在未使用完之前，不能被其他线程强行剥夺。
4. 循环等待条件：若干资源之间形成一种头尾相接的循环等待资源关系。

只要系统发生死锁，就存在以上的四个条件，也就是说只有当以上四个条件同时满足时，才可能引起系统产生死锁，只要系统去掉上述四个条件中的一个，就可以防止死锁的发生。

:::

### ❓主线程是相对于什么而言的

::: details 💡

主线程是相对于其他被该程序创建的子线程而言的。

通常，当一个程序开始运行时，操作系统会为它创建一个线程，这个线程就是主线程。在程序运行过程中，主线程可以再创建更多的子线程。

在多线程编程中，主线程通常负责执行程序的主要部分，而子线程则执行一些特定任务，例如进行输入/输出处理，进行计算等后台任务。

主线程在程序启动时自动创建，当主线程结束时，程序也就结束了。即使程序中还有其他的子线程在运行，一旦主线程结束，所有其他线程也会被强制结束。

:::

### ❓常见的线程同步策略

::: details 💡

线程同步的策略主要用来确保两个或多个并发线程不会同时访问某些共享的资源或者执行某个特定的代码段。这是操作系统中对线程并发控制的基本方法，主要有以下几种：

1. 互斥量（Mutex）：互斥量是一种用于保护共享资源的方法。当一个线程A访问一个被互斥量保护的资源时，它需要首先获得互斥量，访问结束后，需释放互斥量，然后其他的想要访问该资源的线程才能获得互斥量。

2. 信号量（Semaphore）：信号量是一个用来控制一个或者多个线程访问共享资源的数值。当一个线程访问资源时，信号量的值就会递减，当信号量的值为0时，其他线程只能等待；只有当信号量的值大于0时，线程才可以访问资源。

3. 读写锁（ReadWrite Lock）：读写锁允许多个线程同时读取数据，而写入则在整个过程中都无法被其他线程进行读写。

4. 事件（Event）/条件变量（Condition variables）：事件或者条件变量是当某个线程改变了某种条件状态时，通知其他在等待这个条件的线程继续运行。

5. 管理员管道（Barriers）： 管理员管道是一种多线程同步方法，它可以使在并行计算中的线程在继续执行前等待至其他所有的线程都执行到这一位置。

选择哪种同步策略是根据程序结构和需求决定的。

:::

### ❓`sqlite` 中的读写是线程安全的吗

::: details 💡

`SQLite` 本身支持多线程访问，但是线程安全性取决于在编译 `SQLite` 库时的设置。

`SQLite` 在几个不同的线程安全级别下运行，这取决于编译时的配置选项：

- 当 `SQLite` 被编译到非线程安全（`SQLITE_THREADSAFE=0`）模式时，它不允许多线程访问，某些线程安全的假设就无法保证了。

- 在多线程模式（`SQLITE_THREADSAFE=1`）下，核心 `SQLite` 库可以被多个线程同时安全访问，但是每个线程都需要使用一个不同的数据库连接。

- 当 `SQLite` 在序列化模式（`SQLITE_THREADSAFE=2`）下编译时，核心 `SQLite` 库可以被多个线程同时使用，并且一个数据库连接也能在多个线程之间共享。

:::

------

## 线程锁

### ❓线程锁有哪些，那个性能最差

::: details 💡

- 读写锁(read/write-lock)
- 互斥锁(mutex-lock)
- 自旋锁(spin-lock)
- 递归锁(recursive-lock)

- 悲观锁
- 乐观锁

常见的线程锁类型有以下几种：

1. 自旋锁（Spinlock）：当试图获取自旋锁时，如果锁已经被占用，线程并不会被阻塞挂起，而是忙等待，不断尝试获取锁。适用于保护的临界区时间非常短的情况。

2. 互斥锁（Mutex）：与自旋锁不同，如果互斥锁已经被占用，尝试获取锁的线程会进入睡眠状态。

3. 读写锁（Read-Write Lock）：特殊的锁，允许多个读者同时访问，但是在写者访问时，所有的其他读者和写者都会被阻塞。

4. 递归锁（Recursive Mutex）：允许同一个线程对用一个互斥体多次上锁。

至于哪种性能最差，这取决于具体的使用场景。如果竞争不激烈，临界区有长有短，mutex可能会比自旋锁慢一点。如果竞争非常激烈，或者临界区非常短，那么自旋锁可能比较慢。读写锁在并发读多写少的场景下性能很高，但在写稍微增多的情况下就会比较慢。递归锁的性能也是依据情况而定的。总的来说，并没有一种锁是性能最差的，需要看具体情况选择合适的锁。

:::

### ❓各种的线程锁的常见使用场景

::: details 💡

1. 互斥锁（Mutex）：用于保护可同时被多个线程访问而引发问题的代码段（临界区）。适用于竞争不激烈，临界区有长有短的情况。

2. 自旋锁（Spinlock）：用于中断处理程序以及高速缓存等内存访问。一般在保证有很高的获得锁成功率，且执行代码时间较短的情况下使用。

3. 读写锁（Read-Write Lock）：适用于读取操作明显多于写入操作的情况。允许多个线程同时对数据进行读取，提高系统处理效率。

4. 递归锁（Recursive Mutex）：可以在同一个线程内多次获取同一把锁，适用于递归函数中需要使用锁的情况。

5. 条件变量（Condition variables）：用在某些线程需要等待特定条件才能继续执行的场景中。

6. 信号量（Semaphore）：主要使用在多个线程同步以及多个线程访问数量有限的资源场景。

7. 屏障（Barrier）：用于多个线程同时等待某个事件发生的场景，例如并行计算中的同步点等。

具体使用哪种类型的锁，取决于具体的应用场景和其需要解决的问题。

:::

### ❓线程锁的底层实现

::: details 💡

线程锁的底层实现通常依赖于操作系统提供的原子操作和系统调用。下面以互斥锁（Mutex）和自旋锁（Spinlock）为例进行说明：

1. 互斥锁（Mutex）：互斥锁的实现主要依赖操作系统的系统调用。当一个线程试图获取已经被锁定的互斥锁时，该线程会被操作系统挂起，并加入等待队列，在锁被释放时，等待队列中的一个或多个线程会被唤醒并重新竞争锁。在Linux系统中，pthread库提供了互斥锁的实现；在Windows系统中，CriticalSection和Mutex函数提供了互斥锁的实现。

2. 自旋锁（Spinlock）：自旋锁的实现主要依赖硬件提供的原子操作（比如x86架构下的cmpxchg指令）。当一个线程试图获取已经被锁定的自旋锁时，该线程会循环执行原子比较并交换操作，直到成功获取锁。由于自旋锁的实现不需要系统调用，所以其效率比互斥锁更高，但是在锁被长时间持有或者竞争激烈的情况下，自旋锁可能会造成CPU资源的浪费。

以上只是说明互斥锁和自旋锁的一种可能的实现方式，实际上，不同的操作系统和硬件平台，线程锁的实现可能会有所不同。不仅如此，为了提高效率，许多高级锁（比如读写锁、递归锁、条件变量等）的实现通常会将多种线程锁和原子操作进行组合使用。

:::

### ❓`CAS` 了解吗

::: details 💡

`CAS`(Compare And Swap) : 比较并交换，是一种实现原子的机制，可以保证一个变量在读、写时的原子性。
    
  基本原理：比较三个操作数，V (内存位置值)、A (原值)、B (新值)，比较 V 与 A，如果相等则将更新内存位置值交换为 B，如果不相等则不做交换操作。最后无论是否进行交换操作，都返回该位置的值。线程1 读取值后，在进行写时，将读取的值与要写入内存位置的值进行比较，这样如果线程2 在线程1 写之前修改了数据，那么比较的时候就会不相等，也就不能写入保证了原子性。
  
  `CAS` 会存在 `ABA` 问题。也就是说线程2 先将 A 修改为了 B，又将 B 修改为了 A，这样线程1 再进行比较时还是相等，但是其实数据已经是修改过了的。而解决 `ABA` 问题最常见的方案就是版本号，也就是每次修改数据时，都会加上一个版本号。原始版本号为 1，而线程1 读取数据时版本号为 1，当线程2 进行 `ABA` 数据修改后，版本号增长为了 3，则线程1 再进行比较时，就会知道 A 是修改后的了，也就不能写入。
  
  CAS全称是Compare and Swap，即比较并交换，是一种无需阻塞的算法，在硬件操作中，这种指令执行的过程是不会被中断的。这个算法涉及三个操作数：内存位置V、预期原值A和新值B。当且仅当内存位置V的值和预期原值A相等，那么处理器就会将该位置值更新为新值B。如果V值和A值不相等（说明已经有其他的线程更新了数据），那么处理器就什么都不会做。

  CAS是一种乐观锁技术，适用于读多写少的情况。优点是不需要预先加锁，避免了加锁的开销，缺点是在数据冲突严重的情况下，CAS可能出现“自旋”的现象，即反复读取数据尝试更新。

:::

### ❓信号量和锁的关系

::: details 💡

信号量（Semaphore）和锁是两种用于控制多线程并发和同步的机制。他们之间的关系可以这样理解：

1. 锁主要用于保护临界区（即一次只能有一个线程访问的代码段），防止出现数据不一致的问题。例如互斥锁（Mutex）可以确保同一时间只有一个线程正在执行某个临界区。

2. 信号量通常用于控制某个资源的可用数量。例如，如果有一个资源有N个可用的实例，可以通过一个初始为N的信号量来控制对它的并发访问。

3. 锁在某种程度上可以被看作是一个初始值为1的信号量，也就是说，锁其实是信号量的一个特例。当线程持有锁时，它实际上是从信号量中获取了一个资源，当线程释放锁时，它实际上是向信号量返回了一个资源。

4. 但是简单互斥锁在功能上不如信号量强大。一个信号量可以控制多个线程对共享资源的访问，而简单的互斥锁通常只允许一个线程在任何时候访问资源。

在使用它们的时候，选择适当的工具取决于你需要解决的问题和线程间的交互。

:::

### ❓信号量有什么功能是锁做不到的

::: details 💡

  互斥锁主要用于保护临界区，确保同一时间只有一个线程能进入临界区进行操作，主要用于实现乐观并发控制。所以互斥锁是一个二元的信号量，其值只能为0或1。

  信号量则有更大的灵活性，它的值可以大于1，意味着它可以控制对一个资源的多次访问。例如，如果你有一个有3个空闲位置的停车场，你可以用一个初始值为3的信号量来控制它。每当有车辆进入时，信号量减1，每当有车辆离开时，信号量加1。当信号量为0时，新来的车辆将会等待，直到有车辆离开为止。这是锁无法实现的。

  另外，信号量还可以用于实现不同线程间的同步操作。例如，有两个线程A和B，B需要等待A完成某个操作后才能开始执行，这时可以通过一个初始值为0的信号量来实现。A完成操作后调用信号量的释放操作V操作，B在开始执行前调用信号量的获取操作P操作，如果此时信号量为0，B将会阻塞等待，直到A执行完V操作为止。

  总的来说，互斥锁主要用于实现资源的排他性访问，而信号量除了可以实现资源的排他性访问外，还可以实现对有限资源的并发控制以及线程间的同步操作。

:::

### ❓如果让你设计读写锁，你怎么设计

::: details 💡

读写锁设计的关键点是允许多个读线程同时进行操作，但在有写线程时，写操作有优先权，并且只允许一个写线程进行操作。以下是一种可能的设计思路：

1. 首先，定义两个互斥锁（mutex）和一个等待读线程的数量（readCount）。其中，一个互斥锁用于保护读写锁的状态（stateLock），另外一个互斥锁用于保护等待读线程的数量（readCountLock）。在初始化时，stateLock被锁定，readCountLock被解锁，readCount设为0。

2. 当一个读线程试图获取锁时，首先获得readCountLock，然后将readCount加1。如果这是第一个读线程（即readCount从0变为1），则尝试获取stateLock。获取成功后，释放readCountLock。此时，可以开始读操作。

3. 当一个读线程完成读操作并试图释放锁时，首先获得readCountLock，然后将readCount减1。如果这是最后一个读线程（即readCount从1变为0），则释放stateLock。然后，释放readCountLock。

4. 当一个写线程试图获取锁时，直接尝试获取stateLock。获取成功后，可以开始写操作。

5. 当一个写线程完成写操作并试图释放锁时，直接释放stateLock。

注意，为了避免出现读线程饥饿（即写线程连续获得锁，导致等待的读线程无法进行读操作）的情况，可以通过增加一个等待写线程的数量（writeCount）和相应的互斥锁（writeCountLock）来进行限制。具体的，当一个读线程试图获取锁但发现有等待的写线程时，可以选择等待，直到没有等待的写线程为止。

:::

------
  
## 分布式

## ❓说一说分布式锁

::: details 💡

  分布式锁是在分布式环境（多个服务器、多个进程）中，对共享资源进行访问控制的一种机制。在进行一些需要保持互斥性（即同一时间只能有一个任务执行）的操作时，为了避免并发导致的数据不一致，需要使用分布式锁来保证这种互斥性。

常用的一些分布式锁方案包括：

1. 基于数据库的分布式锁：通过在数据库中创建一个锁表，表中包含了锁的信息。当一个进程需要获取锁时，会向这个表中插入一行数据，如果插入成功，那么就获取了锁。当进程完成操作后，会删除这行数据释放锁。优点是实现简单，但是存在性能瓶颈和单点故障问题。

2. 基于Redis的分布式锁：利用Redis的setnx（SET if Not eXists）命令原子性，尝试向某个key写入数据，如果写入成功则获取锁，结束后删除key释放锁。使用Lua脚本可以更安全地实现锁的释放。优点是性能好，适合轻量级锁，但是无法防止锁被长时间占用的问题。

3. 基于ZooKeeper的分布式锁：ZooKeeper是一个开放源码的分布式协调服务，它是集群的管理者，监视着集群中各个节点的状态根据节点提交的反馈进行下一步合理操作。通过其提供的临时有序节点可以实现公平的分布式锁。优点是能实现公平锁，同时有较好的容错性和可靠性，但是使用相对复杂，性能较Redis锁差。

4. 基于分布式一致性算法（如Paxos，Raft）实现的分布式锁：这类锁通常会在分布式存储系统中内置，如etcd的分布式锁。优点是安全性、可靠性极高，可以提供阻塞锁和租约锁，但是使用复杂，性能一般。

这些方案各有优势和劣势，一般应根据业务场景、系统环境和对可靠性、性能的需求进行选择。

:::

## ❓如果没有看门狗机制你应该如何解决锁过期的问题

::: details 💡

看门狗通常用于解决分布式系统中的分布式锁过期问题。如果环境中没有看门狗机制，也可以通过以下策略解决锁过期的问题：

1. 锁超时：为锁设置一个合理的超时时间，而非永久锁定。这样避免因为执行期间发生异常导致锁永久持有，影响其它请求获取锁阻塞等待。

2. 锁续期：在获取锁的线程中定期检查，如果锁即将到期，且任务线程并未结束，则重新设置锁的过期时间。

3. 检查-设置模式：只有真正拥有锁的进程才能对锁进行操作。这可以通过在释放锁时检查进程是否仍然拥有该锁来实现。这需要原子操作支持，Redis的Lua脚本可以实现。

4. 闹钟模式：设置一个单独的定时任务（类似看门狗），定时检查超时的锁，然后释放。

以上几种策略都各有优缺点，需要根据实际业务需求去选择。但是无论哪种方式，设计时都需要考虑全局唯一性、加锁解锁的原子性、锁超时自动释放以及处理异常情况。

:::

------
  
## 线程设计
  
### ❓一个线程打印奇数，一个线程打印偶数，打印 1~100

::: details 💡

主要通过线程间的同步和互斥，确保他们交替打印奇数和偶数。 

这里提供一个基于Java的例子：

```java
public class OddEvenPrinter {
    private final Object monitor = new Object();
    private final int limit;
    private volatile int count;

    public OddEvenPrinter(int limit, int start){
        this.limit = limit;
        this.count = start;
    }

    public void print(){
        synchronized(monitor){
            while(count < limit){
                try{
                    System.out.println(Thread.currentThread().getName() + ":" + count++);
                    monitor.notifyAll();
                    monitor.wait();
                } catch (InterruptedException e) {
                    Thread.currentThread().interrupt();
                    return;
                }
            }
            monitor.notifyAll();
        }
    }

    public static void main(String[] args){
        OddEvenPrinter printer = new OddEvenPrinter(100, 1);
        Thread t1 = new Thread(printer::print, "oddThread");
        Thread t2 = new Thread(printer::print, "evenThread");

        t1.start();
        t2.start();
    }
}
```

在这个例子中，我们创建了两个线程，一个打印奇数，一个打印偶数，我们设置了一个公共的打印次数限制（limit）。在打印的方法print()中，每次打印完一个数字后，它就调用monitor.notifyAll()唤醒其他在wait的线程，然后自己调用monitor.wait()进入等待状态。这样，两个线程就可以一直交替打印，直到count达到limit。

以上的例子假设两个线程启动顺序正常，如果更严谨应还应考虑控制打印奇数线程先启动。

:::

### ❓三个线程按照顺序打印 0~100

::: details 💡

如果三个线程按顺序轮流打印0～100，我们依然可以使用同步锁的机制来保证顺序。

这是一个Java版本的示例：

```java
public class SequencePrinter {
    private final Object monitor = new Object();
    private final int limit;
    private volatile int count;

    public SequencePrinter(int limit, int start){
        this.limit = limit;
        this.count = start;
    }

    public void print(int threadId) {
        synchronized(monitor) {
            while (count < limit) {
                if (count % 3 != threadId) {
                    try {
                        monitor.wait();
                    } catch (InterruptedException e) {
                        Thread.currentThread().interrupt();
                        return;
                    }
                } else {
                    System.out.println("Thread " + threadId + ": " + count);
                    count++;
                    monitor.notifyAll();
                }
            }
        }
    }

    public static void main(String[] args) {
        SequencePrinter printer = new SequencePrinter(100, 0);
        new Thread(() -> printer.print(0)).start();
        new Thread(() -> printer.print(1)).start();
        new Thread(() -> printer.print(2)).start();
    }
}
```

上述代码中定义了三个线程0, 1, 2，他们依次打印数字。每个线程在打印时，首先检查当前数值是否应由自己打印（通过检查count % 3是否等于自己的id），如果不是就等待，如果是就打印并通知所有等待的线程。

请注意这只是一个基本示例，实际情况中可能需要处理更复杂的并发和同步问题。

:::

### ❓需要请求 200 个URL，一次性只能发送10个，该怎么在最短的时间内请求完

::: details 💡

这个问题的本质在于对并发进行限制，即并发控制或者任务分发。这在很多实际工程场景中都非常常见，比如Web爬虫，或者批量请求外部服务等。解决这个问题可以使用一种策略叫做「Semaphore（信号量）」，或者使用线程池进行并发数量的控制。

具体的，信号量可以限制同时进行的操作数量。比如Java中的`java.util.concurrent.Semaphore`类，可以做到这个，其参数为允许同时执行的线程数量。

关于线程池方式，我们可以创建一个最大容量为10的线程池来并发处理这些请求任务。

以下提供一个基于Java的信号量的控制例子：

```java
import java.util.concurrent.Executors;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Semaphore;

public class UrlRequester {
    private static final int MAX_THREADS = 10;
    private final Semaphore semaphore;
    private final ExecutorService threadPool;

    public UrlRequester(int maxUrlConnections) {
        this.semaphore = new Semaphore(maxUrlConnections);
        this.threadPool = Executors.newFixedThreadPool(MAX_THREADS);
    }

    public void requestUrls(List<String> urls) throws InterruptedException {
        for (String url : urls) {
            semaphore.acquire();

            threadPool.execute(() -> {
                try {
                    requestUrl(url);
                } finally {
                    semaphore.release();
                }
            });
        }

        // 确保已提交的任务全部执行完毕
        threadPool.shutdown();
        while (!threadPool.isTerminated()) {}
    }

    private void requestUrl(String url) {
        // 请求url的代码-需要自定义
    }
}
```
其中，首先创建一个线程池来处理任务，然后创建一个Semaphore对象来控制同时处理的任务数。然后，对于每一个URL，通过调用Semaphore的acquire()方法来获取一个许可证，如果无法获取（也就是说已经有10个任务在执行）它会阻塞。然后，在一个新的线程中处理URL请求，在处理结束后，调用Semaphore的release()方法来释放许可证。这样，就能确保同一时刻最多只有10个URL请求在执行。

:::