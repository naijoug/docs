---
title: thread - “多线程”
icon: hashtag

index: true

---

<!-- more -->

------

## 概念知识

### ❓说说你理解的多线程

::: details 💡

> 多线程：程序中包含两个或者更多个可以同时运行的部分，这两个或者多个部分互相独立但又共享某些资源，可以并行执行的每个独立的运行部分就是一个线程。

  每个线程都有它自己的程序计数器、一组寄存器和堆栈，这些都是线程从被暂停到再次被执行所必需的，而尽管每个线程都有自己的堆栈，但是该线程所对应的进程的所有线程都共享同样的地址空间，它们就像是属于同一个进程下的兄弟。

多线程的优点：

  - 充分利用多核处理器的计算能力，一台多核 CPU 计算机上的多线程程序可以使用更多的核，从而提高程序的性能。

  - 提高程序的响应速度，用户界面的多线程设计可以保证用户界面始终对用户的操作做出响应，并且可以做到许多耗时的操作和用户界面的独立处理。

  - 简化复杂的程序设计。一些需要同时处理多个用户请求或者需要连续完成处理一系列任务的软件，使用多线程可以很好地解耦和简化程序设计，提高程序设计的效率。

多线程的缺点：

  - 线程并发执行时可能需要访问同一块资源（如全局变量），这就会带来同步和互斥问题。
    > 例如，经典的生产者消费者问题，读者写者问题等。

  - 多线程技术需要操作系统的支持，不是所有的操作系统或者编程语言都适合编写多线程程序。多线程编程通常需要一些复杂的技巧和细心的设计。

  - 多线程程序的调试和测试比单线程的程序更为困难，因为由于线程是并发执行的，每个线程都有自己独立的上下文，导致线程的执行顺序无法预测。

:::

### ❓并行 vs 串行

::: details 💡

  - 并行：两个或更多任务（或进程）在同一时刻进行，也就是说它们是同时执行的。
    * 如果是多核 `CPU` 会是真正意义上并行，多个任务会在不同 `CPU` 上同时运行
    * 如果是单核 `CPU` 是一种伪并行，是同一时间间隔上运行多个任务，`CPU` 在多个任务上切换运行，其实某一时刻上其实只有一个任务执行，由于 `CPU` 运行速度比较快，用户角度观察呈现并发状态。
    > 比如，超市的几个结账通道就可以同时服务多个顾客，这就是一个并行的例子。
  
  - 串行：在一段时间段内同一时间点只处理一个任务或进程。
    > 在任务一完成之后任务二才可以开始，比如一个人在超市逐个挑选商品，从牛奶到面包再到鸡蛋，这个过程就是串行的。

:::

### ❓进程 vs 线程 vs 协程

::: details 💡

  - 进程(Process) : 程序的一次运行活动，各个进程之间相互资源独立。操作系统分配资源的基本单位，具有唯一的 PID 和 port 号。
  - 线程(Thread) : 线程是进程的最小执行单位，同一个进程内的多个线程共享进程内的资源。
  - 协程(Coroutine) : 也被称为“微线程”。运行在用户态，相比于线程具有极高的执行效率和极低的切换成本。

进程、线程、协程都是程序执行流的基本单元，但它们有着明显的区别：

  - 进程(`Process`)：
    * 进程是操作系统资源分配的基本单元，是一个运行中的程序的实例。
    * 进程具有自己独立的内存空间和系统资源。各个进程间的资源不共享，相互隔离，一个进程不能访问另一个进程的资源和内存空间。
    * 进程间的通信(`IPC`)方式复杂，如管道、信号、消息队列、共享内存、套接字等。

  - 线程(`Thread`)：
    * 线程是操作系统任务调度的基本单元，进程内一个相对独立的、可调度的执行单元。同属一个进程的多个线程共享进程的资源。
    * 线程的切换开销小于进程，因为同一个进程下的线程共享内存和资源，状态切换相对简单。
    * 线程间通常可以直接通信，通信开销小。

  - 协程(`Coroutine`)：
    * 协程是一种用户态的轻量级线程，也叫“微线程”，是程序员显式进行调度的，非抢占，对操作系统透明。
    * 协程的切换不涉及系统调用，开销极小。
    * 协程允许有多个入口点，可以在任何地方暂停执行，并在必要时恢复执行，增强了程序的灵活性。

总结：进程、线程和协程，从上到下执行效率越来越高（开销越来越小），但管理和编程复杂度也相应提高。三者并无优劣之分，具体使用哪个需要根据实际情况和需求来判断。

:::

### 进程

#### ❓进程间如何通信

::: details 💡

  操作系统为支持。

`IPC`(`Inter-Process Communication`，进程间通信) 机制：

  - 管道（`Pipe`）：最古老的进程间通信方式，它可用于具有血缘关系的父子进程之间通信。数据在管道中只能从一端流入，从另一端流出，即单向流动。

  - 命名管道（`Named Pipe`）：命名管道也叫 `FIFO`，它是管道的延伸和发展，可用于互不相关的进程间通信。

  - 信号（`Signals`）：一种非常复杂的通信方式，用于通知接收进程某个事件已经发生。

  - 消息队列（`Message Queue`）：由消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息量小，管道只能承载无格式字节流以及缓冲区大小受限等缺点。

  - 信号量（`Semaphore`）：信号量主要作为进程间以及同一进程不同线程之间的同步手段。

  - 共享内存（`Shared Memory`）：映射一段能被其他进程所访问的内存，适用于大量数据的读写。因为数据不需要在进程间来回复制，效率很高。

  - 套接字（`Socket`）：套接字可以用于不同机器之间的进程通信。使用最广泛的 `IPC` 方式。

  - 内存映射（`Memory Mapping`）：类似于共享内存，允许不同进程访问同一段物理内存。应用于大数据的处理和文件的读写。

:::

#### ❓最多能开辟多少个进程

::: details 💡

  - 在 `Linux` 系统中，可以使用 `ulimit -u` 命令来查看单个用户最多可以开辟的进程数。还可以通过读取/修改 `/proc/sys/kernel/pid_max` 文件，来查看/修改系统整体可以分配的最大进程 `ID`，从而了解系统最多可以支持的进程数。
    > 在早些年的 `Linux` 版本中，默认最大进程数为 `32768`，而在较新的版本中，这个数值通常大得多。

  - 在 `Windows` 系统中，系统同样有最大进程数的限制，但这个限制通常来说远大于普通 `PC` 的资源能应付的范围，因此实际上能开辟多少个进程，更多的是取决于系统的资源情况，当物理和虚拟内存被消耗光时，系统就不能再创建新的进程了。
    
:::

#### ❓进程 A 和进程 B 通过管道通信的话是在同一个管道吗

::: details 💡

  管道（`Pipe`）是半双工的，数据只能向一个方向流动。也就是说，如果进程 A 需要发送数据给进程 B，同时进程 B 又需要发送数据给进程 A，那么就需要创建两个管道，一个管道用于 A 到 B 的通信，另一个管道用于 B 到 A 的通信。

结论：如果进程 A 和进程 B 需要进行双向的数据传输，那么是需要两个管道的，一个用于 A 发送数据至 B，另一个用于 B 发送数据至 A。

:::

#### ❓为什么进程切换比线程切换开销要大

::: details 💡

  - 进程和线程主要的区别在于是否共享内存空间。每个进程都有单独的内存空间，而同一进程内的线程共享该进程的内存空间。因此，进程切换需要进行内存空间的切换，而线程切换不需要。
    
  - 内存切换也意味着需要刷新 `CPU` 的缓存，因为后一个进程的内存和前一个进程的内存并不是同一块内存，刷新缓存就需要将这块内存的信息加载到 `CPU` 中，这个过程的开销是相当大的。
    
  - 在进程切换过程中，操作系统需要保存和恢复更多的上下文信息。线程的上下文信息相对较少，保存和恢复的速度会更快。
    
  - 进程切换涉及到的系统调用更多，比如需要经过调度器的调度，需要进行权限的检查等，而线程切换相对较少。
    
::: 

### 线程

#### ❓线程间的通信方式

::: details 💡

线程间的通信方式主要依赖于它们共享的数据结构、变量等资源。

  - 锁机制：提供了保护共享数据访问的方式，用于控制哪个线程可以访问共享数据。
    > 例如，互斥锁（`Mutex`）用于保护共享资源，确保同一时间只有一个线程可以访问这个资源。

  - 信号量：主要用于同步线程的执行顺序。
    > 例如有两个线程，一个线程完成一项任务后，另一个线程才能开始任务，那么就需要用到信号量。

  - 条件变量：用于等待条件的满足以便继续执行。
    > 例如有两个线程，一个生产者线程和一个消费者线程，消费者线程可能需要等待生产者生产出产品后才能继续执行，那么就需要用到条件变量。
    
  - 事件：线程可以调用事件 `API` 来设置或者等待某个事件的发生，从而实现线程间的通信。

  - 共享内存：线程间也可以通过共享内存来通信，同一进程的所有线程都共享该进程的全局内存，所以线程之间可以方便地访问相同的数据。

:::

#### ❓最多能开辟多少个线程

::: details 💡
    
  - 在 `Linux` 系统中，一个进程的线程个数同样受内存大小限制。理论上，一个进程中的线程数最大可以达到系统进程的上限，通过修改 `ulimit -u`选项可以改变这一限制。但是实际的数量会远小于这个值，因为每个线程都会消耗一定数量的系统资源。 
    
  - 在 `Windows` 系统中，一个进程内部线程的数量主要取决于可用的虚拟内存和线程堆栈大小。
    > 例如，如果使用默认的 `1MB` 线程堆栈大小，那么一个进程最多可以创建约 `2000` 个线程。如果减小线程堆栈的大小，可以创建更多的线程，但是过小的线程堆栈可能导致堆栈溢出。

:::

#### ❓常见的线程同步策略

::: details 💡

  - 互斥量（`Mutex`）：互斥量是一种用于保护共享资源的方法。当一个线程A访问一个被互斥量保护的资源时，它需要首先获得互斥量，访问结束后，需释放互斥量，然后其他的想要访问该资源的线程才能获得互斥量。

  - 信号量（`Semaphore`）：信号量是一个用来控制一个或者多个线程访问共享资源的数值。当一个线程访问资源时，信号量的值就会递减，当信号量的值为 0 时，其他线程只能等待；只有当信号量的值大于 0 时，线程才可以访问资源。

  - 读写锁（`ReadWrite Lock`）：读写锁允许多个线程同时读取数据，而写入则在整个过程中都无法被其他线程进行读写。

  - 事件（`Event`）/条件变量（`Condition variables`）：事件或者条件变量是当某个线程改变了某种条件状态时，通知其他在等待这个条件的线程继续运行。

  - 管理员管道（`Barriers`）： 管理员管道是一种多线程同步方法，它可以使在并行计算中的线程在继续执行前等待至其他所有的线程都执行到这一位置。

:::

#### ❓主线程是相对于什么而言的

::: details 💡

主线程是相对于其他被该程序创建的子线程而言的。

  - 创建：
    * 主线程：当一个程序开始运行时，操作系统会为它创建一个线程，这个线程就是主线程。
    * 子线程：在程序运行过程中，主线程可以再创建更多的子线程。

  - 运行：
    * 主线程：在多线程编程中，主线程通常负责执行程序的主要部分。
    * 子线程：子线程则执行一些特定任务，例如进行输入/输出处理，进行计算等后台任务。

  - 结束：
    * 主线程：主线程在程序启动时自动创建，当主线程结束时，程序也就结束了。即使程序中还有其他的子线程在运行。
    * 子线程：子线程执行特定任务结束，可以通过结束子线程。一旦主线程结束，所有其他子线程也会被强制结束。

:::

#### ❓说说编程语言都开始支持的 `async/await`

::: details 💡

> `async/await` 是现今很多编程语言支持的一种特性。这两个关键词能够使异步操作（比如文件读取、网络请求、定时操作等）更像是同步操作，有助于简化代码逻辑和提高代码可读性。

原理：`async` 用于声明一个函数为异步函数，异步函数内部可以使用 `await` 关键词来等待一个异步操作返回。`async` 函数返回的结果是一个 `Promise` 对象（或者类似的 `Future` 对象），这个对象表示的是一个尚未完成的异步操作。

优点：使用 `async/await` 编程模型，可以使得原本需要使用回调（`Callback`）或者 `Promise` 来处理的异步结果，能够以同步的方式来编写和读取，大大简化了异步编程的难度，提高代码的可读性和可维护性。

支持的编程语言：

  - `Python` : 在 `3.5` 版本中新增，内置了对异步 `IO` 的支持
  - `JavaScript` : 在 `ES7` 规范中引入，现今主流的 `JS` 运行环境如浏览器和 `Node.js` 均已支持
  - `TypeScript` : 微软开发的 `JavaScript` 的超集语言，支持 `async/await`，并可以编译到 `ES5/ES3` 等不支持这个特性的 `JS` 版本上运行
  - `C#` : 在 `5.0` 版本中引入，主要用于异步 `IO` 操作和任务的等待
  - `Dart` : `Google` 开发的一种语言，用于 `Flutter` 框架开发，支持 `async/await`
  - `Rust` : 新兴的系统编程语言，从 `1.39` 版本开始对 `async/await` 提供稳定支持。

:::

------

## 线程安全

### ❓什么是线程安全

::: details 💡

> 线程安全：多线程环境下，当多个线程访问某一个对象或程序时，不会对程序的执行和对象所产生的影响进行破坏，始终表现出正确的行为，就称这段代码是线程安全的。

🌰 考虑一个程序其运行环境有多个线程，这个程序会被多个线程共享并进行写操作，如果每次运行结果和预期的一样，那么就是线程安全的。反之，所谓的非线程安全就是程序的运行结果会受到多线程的影响。

:::

### 死锁

#### ❓死锁(`deadlocks`) vs 活锁(`livelocks`)

::: details 💡

> 死锁：两个或更多的线程被永久阻塞，等待彼此采取行动的情况。这发生在每一个线程都在等待另一个线程所拥有的资源。它们都无法继续执行，因为每个线程都需要等待另一个线程释放资源。

> 活锁：两个或多个线程持续改变它们的状态以响应对方的状态，令它们都无法进行的情况。有点像两个人在门口互相礼让，结果都不能进门。活锁的线程能够执行，但不能完成有实际结果的任务，因为它们还在互相等待。

主要区别：

  - 在死锁中，进程/线程都停止执行，而在活锁中，它们继续执行，但不能做出实质性的进行。
  - 从外界观察，死锁看上去就像是没有运行的程序，而活锁则像是在做无尽的忙碌等待。
  - 对于死锁，可以通过恢复某些资源将其解开。但对于活锁，这可能就需要更复杂的操作，例如需要终止整个过程或者是调整其执行顺序。

:::

#### ❓线程死锁的四个条件

::: details 💡

> 死锁：多个线程永久性地阻塞，无法继续执行的状态。这经常发生在每个线程都在等待其他线程释放它们需要的资源，而这个资源又正被等待释放它的线程持有。

四个必要条件共同存在：

  - 互斥条件：一个资源每次只能被一个线程使用，即在一段时间内某资源只为一个线程所占有，此时若有其他线程请求该资源，则请求者只能等待。
  - 请求和保持条件：一个线程因请求占有其他资源而阻塞时，对已获得的资源保持不放。
  - 不剥夺条件：线程已经获得的资源，在未使用完之前，不能被其他线程强行剥夺。
  - 循环等待条件：若干资源之间形成一种头尾相接的循环等待资源关系。

  只要系统发生死锁，就存在以上的四个条件，也就是说只有当以上四个条件同时满足时，才可能引起系统产生死锁，只要系统去掉上述四个条件中的一个，就可以防止死锁的发生。

:::

------

## 线程锁

### ❓线程锁有哪些

::: details 💡

  - 自旋锁（`Spin-lock`）：当试图获取自旋锁时，如果锁已经被占用，线程并不会被阻塞挂起，而是忙等待，不断尝试获取锁。适用于保护的临界区时间非常短的情况。

  - 互斥锁（`Mutex-lock`）：与自旋锁不同，如果互斥锁已经被占用，尝试获取锁的线程会进入睡眠状态。

  - 读写锁（`Read-Write Lock`）：特殊的锁，允许多个读者同时访问，但是在写者访问时，所有的其他读者和写者都会被阻塞。

  - 递归锁（`Recursive Lock`）：允许同一个线程对用一个互斥体多次上锁。

:::

### ❓各种的线程锁的常见使用场景

::: details 💡

  - 互斥锁（`Mutex`）：用于保护可同时被多个线程访问而引发问题的代码段（临界区）。适用于竞争不激烈，临界区有长有短的情况。

  - 自旋锁（`Spinlock`）：用于中断处理程序以及高速缓存等内存访问。一般在保证有很高的获得锁成功率，且执行代码时间较短的情况下使用。

  - 读写锁（`Read-Write Lock`）：适用于读取操作明显多于写入操作的情况。允许多个线程同时对数据进行读取，提高系统处理效率。

  - 递归锁（`Recursive Mutex`）：可以在同一个线程内多次获取同一把锁，适用于递归函数中需要使用锁的情况。

  - 条件变量（`Condition variables`）：用在某些线程需要等待特定条件才能继续执行的场景中。

  - 信号量（`Semaphore`）：主要使用在多个线程同步以及多个线程访问数量有限的资源场景。

  - 屏障（`Barrier`）：用于多个线程同时等待某个事件发生的场景，例如并行计算中的同步点等。
  
:::

### ❓线程锁的底层实现

::: details 💡

线程锁的底层实现通常依赖于操作系统提供的原子操作和系统调用。

  - 互斥锁（`Mutex`）：主要依赖操作系统的系统调用。
    > 当一个线程试图获取已经被锁定的互斥锁时，该线程会被操作系统挂起，并加入等待队列，在锁被释放时，等待队列中的一个或多个线程会被唤醒并重新竞争锁。
    * 在 `Linux` 系统中，`pthread` 库提供了互斥锁的实现。
    * 在 `Windows` 系统中， `CriticalSection` 和Mutex函数提供了互斥锁的实现。

  - 自旋锁（Spinlock）：自旋锁的实现主要依赖硬件提供的原子操作（比如 `x86` 架构下的 `cmpxchg` 指令）。
    > 当一个线程试图获取已经被锁定的自旋锁时，该线程会循环执行原子比较并交换操作，直到成功获取锁。由于自旋锁的实现不需要系统调用，所以其效率比互斥锁更高，但是在锁被长时间持有或者竞争激烈的情况下，自旋锁可能会造成 `CPU` 资源的浪费。

:::

### 信号量

#### ❓信号量和锁的关系

::: details 💡

信号量（`Semaphore`）和锁是两种用于控制多线程并发和同步的机制。

作用：
  
  - 锁：用于保护临界区（即一次只能有一个线程访问的代码段），防止出现数据不一致的问题。
    > 例如，互斥锁（`Mutex`）可以确保同一时间只有一个线程正在执行某个临界区。

  - 信号量：用于控制某个资源的可用数量。
    > 例如，如果有一个资源有 N 个可用的实例，可以通过一个初始为 N 的信号量来控制对它的并发访问。

关系：

  - 锁在某种程度上可以被看作是一个初始值为 1 的信号量，也就是说，锁其实是信号量的一个特例。当线程持有锁时，它实际上是从信号量中获取了一个资源，当线程释放锁时，它实际上是向信号量返回了一个资源。

  - 简单互斥锁在功能上不如信号量强大。一个信号量可以控制多个线程对共享资源的访问，而简单的互斥锁通常只允许一个线程在任何时候访问资源。
  
:::

#### ❓信号量有什么功能是锁做不到的

::: details 💡

  - 互斥锁主要用于保护临界区，确保同一时间只有一个线程能进入临界区进行操作，主要用于实现乐观并发控制。所以互斥锁是一个二元的信号量，其值只能为 0 或 1。

  - 信号量则有更大的灵活性，它的值可以大于 1，意味着它可以控制对一个资源的多次访问。
    > 例如，如果有一个有 3 个空闲位置的停车场，可以用一个初始值为 3 的信号量来控制它。每当有车辆进入时，信号量减 1，每当有车辆离开时，信号量加 1。当信号量为 0 时，新来的车辆将会等待，直到有车辆离开为止。这是锁无法实现的。

  总结：互斥锁主要用于实现 “资源的排他性访问”；而信号量除了可以实现 “资源的排他性访问”，还可以实现对 “有限资源的并发控制” 以及线程间的同步操作。
  
:::

### 锁设计

#### ❓`CAS` 了解吗

::: details 💡

- 概念知识：
    > `CAS`(Compare And Swap) : 比较并交换，是一种实现原子的机制，可以保证一个变量在读、写时的原子性。是一种乐观锁技术，适用于读多写少的情况。
  
  * 优点：不需要预先加锁，避免了加锁的开销，
  * 缺点：在数据冲突严重的情况下，CAS可能出现“自旋”的现象，即反复读取数据尝试更新。
    
- 基本原理：
    > 比较三个操作数，`V (内存位置值)、A (原值)、B (新值)`。比较 `V` 与 `A`，如果相等则将更新内存位置值交换为 `B`，如果不相等则不做交换操作。最后无论是否进行交换操作，都返回该位置的值。
  
  `线程1` 读取值后，在进行写时，将读取的值与要写入内存位置的值进行比较，这样如果 `线程2` 在 `线程1` 写之前修改了数据，那么比较的时候就会不相等，也就不能写入保证了原子性。
  
- 🐛`ABA` 问题 (“自旋”现象)：
    > `线程2` 先将 `A` 修改为了 `B`，又将 `B` 修改为了 `A`，这样 `线程1` 再进行比较时还是相等，但是其实数据已经是修改过了的。
    
- 💡解决方案：版本号，也就是每次修改数据时，都会加上一个版本号。
    > 原始版本号为 1，而 `线程1` 读取数据时版本号为 1，当 `线程2` 进行 `ABA` 数据修改后，版本号增长为了 3，则 `线程1` 再进行比较时，就会知道` A` 是修改后的了，也就不能写入。

:::

#### ❓如果让你设计读写锁，你怎么设计

::: details 💡

读写锁设计的关键点是允许多个读线程同时进行操作，但在有写线程时，写操作有优先权，并且只允许一个写线程进行操作。

设计思路：

  - 定义两个互斥锁（`mutex`）和一个等待读线程的数量（`readCount`）。
    * 一个互斥锁用于保护读写锁的状态（`stateLock`），
    * 另外一个互斥锁用于保护等待读线程的数量（`readCountLock`）。
    * 在初始化时，`stateLock` 被锁定，`readCountLock` 被解锁，`readCount` 设为 0。
    
  - 当一个读线程试图获取锁时，首先获得 `readCountLock`，然后将 `readCount` 加 1。如果这是第一个读线程（即 `readCount` 从 0 变为 1），则尝试获取 `stateLock`。获取成功后，释放 `readCountLock`。此时，可以开始读操作。

  - 当一个读线程完成读操作并试图释放锁时，首先获得 `readCountLock`，然后将 `readCount` 减 1。如果这是最后一个读线程（即 `readCount` 从 1 变为 0），则释放 `stateLock`。然后，释放 `readCountLock`。
    
  - 当一个写线程试图获取锁时，直接尝试获取 `stateLock`。获取成功后，可以开始写操作。
    
  - 当一个写线程完成写操作并试图释放锁时，直接释放 `stateLock`。

注意，为了避免出现读线程饥饿（即写线程连续获得锁，导致等待的读线程无法进行读操作）的情况，可以通过增加一个等待写线程的数量（`writeCount`）和相应的互斥锁（`writeCountLock`）来进行限制。具体的，当一个读线程试图获取锁但发现有等待的写线程时，可以选择等待，直到没有等待的写线程为止。

:::

#### ❓如果没有看门狗机制你应该如何解决锁过期的问题

::: details 💡

看门狗通常用于解决分布式系统中的分布式锁过期问题。

> 看门狗（`Watchdog`）机制是一种常见的硬件或软件设施，用于检测系统故障并采取恢复措施，确保系统可靠和稳定运行。
 
工作原理：

  - 在系统启动后，看门狗定时器开始计时。时间间隔是有系统设置的，例如1秒钟。

  - 在正常运行时，系统周期性地（比如每0.5秒钟）向看门狗发送一个“我还活着”的信号，也叫做“喂狗”操作，重置看门狗定时器。

  - 如果系统运行发生问题，无法正常喂狗，比如有某个重要的线程卡死了，那么看门狗定时器会继续计时，直到计时时间结束。

  - 当看门狗定时器时间到了，如果还未收到系统“喂狗”的信号，它就判断系统发生了故障，然后执行预定义的恢复操作。最常见的恢复操作是硬重启系统。

如果环境中没有看门狗机制的方案：

  - 锁超时：为锁设置一个合理的超时时间，而非永久锁定。这样避免因为执行期间发生异常导致锁永久持有，影响其它请求获取锁阻塞等待。

  - 锁续期：在获取锁的线程中定期检查，如果锁即将到期，且任务线程并未结束，则重新设置锁的过期时间。

  - 检查-设置模式：只有真正拥有锁的进程才能对锁进行操作。这可以通过在释放锁时检查进程是否仍然拥有该锁来实现。这需要原子操作支持，`Redis` 的 `Lua` 脚本可以实现。

  - 闹钟模式：设置一个单独的定时任务（类似看门狗），定时检查超时的锁，然后释放。

:::

#### ❓说一说分布式锁

::: details 💡

  > 分布式锁是在分布式环境（多个服务器、多个进程）中，对共享资源进行访问控制的一种机制。在进行一些需要保持互斥性（即同一时间只能有一个任务执行）的操作时，为了避免并发导致的数据不一致，需要使用分布式锁来保证这种互斥性。

分布式锁方案：

  - 基于数据库的分布式锁：通过在数据库中创建一个锁表，表中包含了锁的信息。当一个进程需要获取锁时，会向这个表中插入一行数据，如果插入成功，那么就获取了锁。当进程完成操作后，会删除这行数据释放锁。
    * 优点：实现简单。
    * 缺点：存在性能瓶颈和单点故障问题。

  - 基于 `Redis` 的分布式锁：利用 `Redis` 的 `setnx`（`SET if Not eXists`）命令原子性，尝试向某个 `key` 写入数据，如果写入成功则获取锁，结束后删除 `key` 释放锁。使用 `Lua` 脚本可以更安全地实现锁的释放。
    * 优点：性能好，适合轻量级锁。
    * 缺点：无法防止锁被长时间占用的问题。

  - 基于 `ZooKeeper` 的分布式锁：`ZooKeeper` 是一个开放源码的分布式协调服务，它是集群的管理者，监视着集群中各个节点的状态根据节点提交的反馈进行下一步合理操作。通过其提供的临时有序节点可以实现公平的分布式锁。
    * 优点：能实现公平锁，同时有较好的容错性和可靠性。
    * 缺点：使用相对复杂，性能较 `Redis` 锁差。

  - 基于分布式一致性算法（如`Paxos`，`Raft`）实现的分布式锁：这类锁通常会在分布式存储系统中内置，如 `etcd` 的分布式锁。
    * 优点：安全性、可靠性极高，可以提供阻塞锁和租约锁。
    * 缺点：使用复杂，性能一般。

:::

------
  
## 线程设计
  
### ❓一个线程打印奇数，一个线程打印偶数，打印 1~100

::: details 💡

主要通过线程间的同步和互斥，确保他们交替打印奇数和偶数。 

::: code-tabs

@tab java
```java
public class PrintOddEven {
    private int count;
    private final Object lock = new Object();

    public PrintOddEven(int count) {
        this.count = count;
    }
    // 打印奇数
    public void printOdd() {
        for (int i = 1; i < count; i += 2) {
            synchronized(lock) {
                System.out.println("Odd Thread: " + i);
                lock.notifyAll();
                try {
                    if (i < count - 1) {
                        lock.wait();
                    }
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
            }
        }
    }
    // 打印偶数
    public void printEven() {
        for (int i = 2; i <= count; i += 2) {
            synchronized(lock) {
                System.out.println("Even Thread: " + i);
                lock.notifyAll();
                try {
                    if (i < count) {
                        lock.wait();
                    }
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
            }
        }
    }

    public static void main(String[] args) {
        PrintOddEven printer = new PrintOddEven(100);
        Thread oddThread = new Thread(printer::printOdd);
        Thread evenThread = new Thread(printer::printEven);

        oddThread.start();
        evenThread.start();
    }
}
```

@tab python
```py
import threading

class ZeroEvenOdd:
    def __init__(self, n):
        self.n = n
        self.num = 1
        # 使用条件锁控制奇数偶数交替打印
        self.cond = threading.Condition()

    def print_number(self, number):
        print(number)

    def odd(self):
        with self.cond:
            for _ in range(self.n // 2 + self.n % 2):
                while self.num % 2 == 0:
                    self.cond.wait()
                self.print_number(self.num)
                self.num += 1
                self.cond.notify_all()

    def even(self):
        with self.cond:
            for _ in range(self.n // 2):
                while self.num % 2 == 1:
                    self.cond.wait()
                self.print_number(self.num)
                self.num += 1
                self.cond.notify_all()


if __name__ == "__main__":
    foo = ZeroEvenOdd(100)
    threading.Thread(target=foo.odd).start()
    threading.Thread(target=foo.even).start()
```

@tab swift
```swift
import Foundation

class PrintOddEven {

    var max: Int
    var count = 1
    let semaphore1 = DispatchSemaphore(value: 0)
    let semaphore2 = DispatchSemaphore(value: 1)

    init(max: Int) {
        self.max = max
    }

    func printOdd() {
        while count <= max {
            semaphore1.wait()  // if semaphore1's value <= 0, then block
            if count <= max {
                print("\(Thread.current) \(count)")
                count += 1
            }
            semaphore2.signal()  // semaphore2's value += 1
        }
    }

    func printEven() {
        while count <= max {
            semaphore2.wait()  // if semaphore2's value <= 0, then block
            if count <= max {
                print("\(Thread.current) \(count)")
                count += 1
            }
            semaphore1.signal()  // semaphore1's value += 1
        }
    }
}

let printer = PrintOddEven(max: 100)
let queue1 = DispatchQueue.global()
let queue2 = DispatchQueue.global()
queue1.async {
    printer.printOdd()
}
queue2.async {
    printer.printEven()
}
dispatchMain()  // to keep the program running
```

:::

### ❓三个线程按照顺序打印 0~100

::: details 💡

::: code-tabs

@tab java
```java
public class NumberPrinter {
    private int number = 0;
    private final Object lock = new Object();

    class PrintThread implements Runnable {
        private final int threadRemainder;

        PrintThread(int remainder) {
            this.threadRemainder = remainder;
        }

        @Override
        public void run() {
            while (true) {
                synchronized (lock) {
                    while (number <= 100) {
                        // 根据线程的余数和数字的余数是否相等，来决定这个线程是否应该打印这个数字
                        if (number % 3 == threadRemainder) {
                            System.out.println(Thread.currentThread().getName() + ": " + number);
                            number++;
                            lock.notifyAll();
                        } else {
                            try {
                                lock.wait();
                            } catch (InterruptedException e) {
                                Thread.currentThread().interrupt();
                                throw new RuntimeException(e);
                            }
                        }
                    }
                }
            }
        }
    }

    public static void main(String[] args) {
        NumberPrinter numberPrinter = new NumberPrinter();
        new Thread(numberPrinter.new PrintThread(0), "Thread1").start();
        new Thread(numberPrinter.new PrintThread(1), "Thread2").start();
        new Thread(numberPrinter.new PrintThread(2), "Thread3").start();
    }
}
```

@tab swift
```swift
import Foundation

// 使用三个信号量来控制三个线程的顺序打印，每次开启一个信号量
let semaphore1: DispatchSemaphore = DispatchSemaphore(value: 1)
let semaphore2: DispatchSemaphore = DispatchSemaphore(value: 0)
let semaphore3: DispatchSemaphore = DispatchSemaphore(value: 0)

var counter: Int = 0

enum ThreadType {
    case Thread1, Thread2, Thread3
}

func threadHandler(threadType: ThreadType, waitOnSemaphore beforeSemaphore: DispatchSemaphore, signalSemaphore afterSemaphore: DispatchSemaphore) {
    while counter <= 100 {
        beforeSemaphore.wait()
        print("\(threadType) : \(counter)")
        counter += 1
        afterSemaphore.signal()
    }
}

let thread1 = Thread()  {threadHandler(threadType: .Thread1, waitOnSemaphore: semaphore1, signalSemaphore: semaphore2)}
let thread2 = Thread()  {threadHandler(threadType: .Thread2, waitOnSemaphore: semaphore2, signalSemaphore: semaphore3)}
let thread3 = Thread()  {threadHandler(threadType: .Thread3, waitOnSemaphore: semaphore3, signalSemaphore: semaphore1)}

[thread1, thread2, thread3].forEach {thread in
    thread.start()
}

[thread1, thread2, thread3].forEach {thread in
    thread.join()
}
```

:::

### ❓需要请求 200 个URL，一次性只能发送10个，该怎么在最短的时间内请求完

::: details 💡

这个问题的本质在于对并发进行限制，即并发控制或者任务分发。这在很多实际工程场景中都非常常见，比如 `Web` 爬虫，或者批量请求外部服务等。解决这个问题可以使用一种策略叫做「`Semaphore`（信号量）」，或者使用线程池进行并发数量的控制。

::: code-tabs

@tab java

```java
import java.util.concurrent.*;
import java.net.*;

public class Main {
    public static void main(String[] args) {
        URL[] urls = new URL[200]; // 200个 URL 需要请求
        for (int i = 0; i < 200; i++) {
            try {
                urls[i] = new URL("http://example.com");
            } catch (MalformedURLException e) {
                e.printStackTrace();
            }
        }

        // 创建一个线程池，每次最多发送 10 个请求
        ExecutorService executor = Executors.newFixedThreadPool(10);

        // submit 方法用于添加请求任务
        for (int i = 0; i < 200; i++) {
            final URL url = urls[i];
            executor.submit(new Runnable() {
                @Override
                public void run() {
                    try {
                        // 假设 fetchData 请求 url 并获取数据的方法
                        fetchData(url);
                    } catch (Exception e) {
                        e.printStackTrace();
                    }
                }
            });
        }
        // 关闭 executor，等待未完成的任务完成
        executor.shutdown();
        try {
            // 设置最大等待时间，例如 1 小时，等待所有任务完成
            if (!executor.awaitTermination(1, TimeUnit.HOURS)) {
                // 如果等待的时间超过了设定的时间，将强制停止所有任务
                executor.shutdownNow();
            }
        } catch (InterruptedException e) {
            executor.shutdownNow();
        }
    }

    // 假设你有一个 fetchData 的方法用于获取数据
    static void fetchData(URL url) {
        // Request the data and process it.
    }
}
```

@tab swift
```swift
let dispatchGroup = DispatchGroup() 
let queue = DispatchQueue(label: "com.queue.serial", attributes: .concurrent)
let urls: [URL] = [] //200 个 URL 放入这个数组中
let chunked = urls.chunked(into: 10) //把 URL 分成每 10 个一组

for urlChunk in chunked {
    dispatchGroup.enter()
    queue.async {
        for url in urlChunk {
            // 发送网络请求
            URLSession.shared.dataTask(with: url){
                (data, response, error) in
                // 处理结果
                if error != nil {
                    print(error!)
                } else {
                    // do something with data.
                }
            }.resume()
        }
        dispatchGroup.leave()
    }
}

dispatchGroup.notify(queue: .main) {
    print("所有的请求都已经完成！")
}

extension Array {
    // 分组
    func chunked(into size: Int) -> [[Element]] {
        return stride(from: 0, to: count, by: size).map {
            Array(self[$0..<Swift.min($0 + size, count)])
        }
    }
}
```

:::