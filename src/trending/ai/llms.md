---
title: LLMs - “大语言模型”
icon: hashtag

index: true

---

> `LLMs`(`Large Language Models`) : 大语言模型

## reference

- [LLM Stats](https://llm-stats.com/) 👉🏻 [🐙](https://github.com/JonathanChavezTamales/LLMStats)
    > A comprehensive set of LLM benchmark scores and provider prices.
- [LLM Leaderboard](https://www.vellum.ai/llm-leaderboard)
- [LM Speed](https://lmspeed.net)
    > 大模型 API 速度测试
- [开源大模型食用指南](https://github.com/datawhalechina/self-llm)
    > 《开源大模型食用指南》基于Linux环境快速部署开源大模型，更适合中国宝宝的部署教程
- [llm-books](https://aitutor.liduos.com/) 👉🏻 [🐙](https://github.com/morsoli/llm-books)
    > 利用 LLM 构建应用实践笔记
- [动手学大模型应用开发](https://datawhalechina.github.io/llm-universe/#/) 👉🏻 [🐙](https://github.com/datawhalechina/llm-universe)
- [Open LLMs](https://github.com/eugeneyan/open-llms)
    > 🤖 A list of open LLMs available for commercial use. 
- [Z-Bench](https://github.com/zhenbench/z-bench)
    > Z-Bench 1.0 by 真格基金：一个麻瓜的大语言模型中文测试集。Z-Bench is a LLM prompt dataset for non-technical users, developed by an enthusiastic AI-focused team in Zhenfund

------

- [anything-llm](https://anythingllm.com/) 👉🏻 [🐙](https://github.com/Mintplex-Labs/anything-llm)
    > The all-in-one Desktop & Docker AI application with built-in RAG, AI agents, No-code agent builder, MCP compatibility, and more.
- [Open WebUI](https://openwebui.com/) 👉🏻 [🐙](https://github.com/open-webui/open-webui)
    > User-friendly AI Interface (Supports Ollama, OpenAI API, ...)
- [Dify](https://dify.ai) 👉🏻 [🐙](https://github.com/langgenius/dify)
    > Dify is an open-source LLM app development platform. Dify's intuitive interface combines AI workflow, RAG pipeline, agent capabilities, model management, observability features and more, letting you quickly go from prototype to production.
- [LiteLLM](https://litellm.ai) 👉🏻 [🐙](https://github.com/BerriAI/litellm)
    > Python SDK, Proxy Server (LLM Gateway) to call 100+ LLM APIs in OpenAI format - [Bedrock, Azure, OpenAI, VertexAI, Cohere, Anthropic, Sagemaker, HuggingFace, Replicate, Groq]

## GPT

- [FastGPT](https://fastgpt.in) 👉🏻 [🐙](https://github.com/labring/FastGPT)
    > FastGPT is a knowledge-based platform built on the LLMs, offers a comprehensive suite of out-of-the-box capabilities such as data processing, RAG retrieval, and visual AI workflow orchestration, letting you easily develop and deploy complex question-answering systems without the need for extensive setup or configuration.
- [GPT4All](https://github.com/nomic-ai/gpt4all) : [Official](https://gpt4all.io)
    > gpt4all: an ecosystem of open-source chatbots trained on a massive collections of clean assistant data including code, stories and dialogue
- [minichatgpt](https://github.com/juncongmoo/minichatgpt) 
    > 🔥 To Train ChatGPT In 5 Minutes with ColossalAI
- [privateGPT](https://github.com/imartinez/privateGPT)
    > Interact privately with your documents using the power of GPT, 100% privately, no data leaks
- [Code Review GPT](https://github.com/mattzcarey/code-review-gpt)
    > Your personal code reviewer powered by LLMs (OpenAI GPT-3.5/4, Llama, Falcon, Azure AI) & Embeddings ⚡️ Improve code quality and catch bugs before you break production 🚀

## LLaMa

- [LLaMA](https://github.com/facebookresearch/llama) : [introducing](https://ai.facebook.com/blog/large-language-model-llama-meta-ai/)
    > Inference code for LLaMA models
- [llama.cpp](https://github.com/ggml-org/llama.cpp)
    > LLM inference in C/C++
- [ChatLLaMa](https://github.com/juncongmoo/chatllama)
    > ChatLLaMA 📢 Open source implementation for LLaMA-based ChatGPT runnable in a single GPU. 15x faster training process than ChatGPT
- [pyllama](https://github.com/juncongmoo/pyllama)
    > 🦙 LLaMA - Run LLM in A Single 4GB GPU

## Alpaca

- [Stanford Alpaca](https//github.com/tatsu-lab/stanford_alpaca)
    > An Instruction-following LLaMA Model
- [alpaca-lora](https://github.com/tloen/alpaca-lora)
    > Instruct-tune LLaMA on consumer hardware
- [Chinese-LLaMA-Alpaca](https://github.com/ymcui/Chinese-LLaMA-Alpaca)
    > 中文LLaMA&Alpaca大语言模型+本地CPU/GPU部署 (Chinese LLaMA & Alpaca LLMs)
- [KoAlpaca](https://github.com/Beomi/KoAlpaca)
    > KoAlpaca: Korean Alpaca Model based on Stanford Alpaca (feat. LLAMA and Polyglot-ko)

## Vicuna

- [FastChat](https://github.com/lm-sys/FastChat)
    > An open platform for training, serving, and evaluating large language models. Release repo for Vicuna and FastChat-T5.
- [Chinese-Vicuna](https://github.com/Facico/Chinese-Vicuna)
    > Chinese-Vicuna: A Chinese Instruction-following LLaMA-based Model —— 一个中文低资源的llama+lora方案，结构参考alpaca
- [WizardVicunaLM](https://github.com/melodysdreamj/WizardVicunaLM)
    > LLM that combines the principles of wizardLM and vicunaLM

## Other

- [DeepSeek-R1](https://github.com/deepseek-ai/DeepSeek-R1)
- [DeepSeek-V3](https://github.com/deepseek-ai/DeepSeek-V3)
- [ChatGLM-6B](https://github.com/THUDM/ChatGLM-6B)
    > ChatGLM-6B: An Open Bilingual Dialogue Language Model | 开源双语对话语言模型
- [Luotuo-Chinese-LLM](https://github.com/LC1332/Luotuo-Chinese-LLM)
    > 骆驼(Luotuo): Open Sourced Chinese Language Models
- [Visual OpenLLM](https://github.com/visual-openllm/visual-openllm)
    > something like visual-chatgpt, 文心一言的开源版
- [wenda](https://github.com/wenda-LLM/wenda)
    > 闻达：一个LLM调用平台。为小模型外挂知识库查找和设计自动执行动作，实现不亚于于大模型的生成能力
- [Linly](https://github.com/CVI-SZU/Linly)
    > Chinese-LLaMA基础模型；ChatFlow中文对话模型；中文OpenLLaMA模型；NLP预训练/指令微调数据集
- [CPM-Bee](https://github.com/OpenBMB/CPM-Bee)
    > 百亿参数的中英文双语基座大模型
    
    
## image 

- [MAGI-1](https://sand.ai/) 👉🏻 [🐙](https://github.com/SandAI-org/MAGI-1)
    > MAGI-1: Autoregressive Video Generation at Scale

------

- [Text generation web UI](https://github.com/oobabooga/text-generation-webui)
    > A Gradio web UI for Large Language Models with support for multiple inference backends.
- [Stable Diffusion web UI](https://github.com/AUTOMATIC1111/stable-diffusion-webui)
    > A web interface for Stable Diffusion, implemented using Gradio library.
    
## cpu

- [BitNet - *microsoft*](https://github.com/microsoft/BitNet)
    > Official inference framework for 1-bit LLMs
    
## local

- [ollama](https://ollama.com/) 👉🏻 [🐙](https://github.com/ollama/ollama)
    > Get up and running with Llama 3.3, DeepSeek-R1, Phi-4, Gemma 3, Mistral Small 3.1 and other large language models.
- [LocalAI](https://localai.io/) 👉🏻 [🐙](https://github.com/mudler/LocalAI)
    > 🤖 The free, Open Source alternative to OpenAI, Claude and others. Self-hosted and local-first. Drop-in replacement for OpenAI, running on consumer-grade hardware. No GPU required. Runs gguf, transformers, diffusers and many more models architectures. Features: Generate Text, Audio, Video, Images, Voice Cloning, Distributed, P2P inference
- [LM Studio](https://lmstudio.ai/) 👉🏻 [🐙](https://github.com/lmstudio-ai/lms)
    > LM Studio CLI
- [vLLM](https://docs.vllm.ai) 👉🏻 [🐙](https://github.com/vllm-project/vllm)
    > A high-throughput and memory-efficient inference and serving engine for LLMs
    
## tutorial

- [Full Stack LLM Bootcamp](https://github.com/the-full-stack/website)
- [基于本地知识库的 ChatGLM 等大语言模型应用实现](https://github.com/imClumsyPanda/langchain-ChatGLM)
- [一种平价的chatgpt实现方案, 基于ChatGLM-6B + LoRA](https://github.com/mymusise/ChatGLM-Tuning)
- [2023-05-18 GPT大语言模型Vicuna本地化部署实践（效果秒杀Alpaca）](https://zhuanlan.zhihu.com/p/630287397)
- [2023-04-22 大模型也内卷，Vicuna训练及推理指南，效果碾压斯坦福羊驼](https://zhuanlan.zhihu.com/p/624012908)
- [2023-01-18 通向AGI之路：大型语言模型（LLM）技术精要](https://zhuanlan.zhihu.com/p/597586623)
- [2019-01-27 BERT大火却不懂Transformer？读这一篇就够了](https://zhuanlan.zhihu.com/p/54356280)
- [2019-01-13 放弃幻想，全面拥抱Transformer：自然语言处理三大特征抽取器（CNN/RNN/TF）比较](https://zhuanlan.zhihu.com/p/54743941)